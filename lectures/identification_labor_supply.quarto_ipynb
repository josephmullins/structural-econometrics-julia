{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Dynamic Labor Supply Model\n",
        "\n",
        "For this example, let's remind ourselves how labor supply looks in this model without heterogeneity and with quasilinear preferences ($\\sigma=0$):\n",
        "\n",
        "$$ \\log(H_{n,t}) = \\psi\\log(\\alpha) + \\psi\\log(W_{n,t}) $$\n",
        "\n",
        "Clearly, we need more assumptions to brings this model to data, since it predicts that the relationship between log hours and log wages is a perfectly straight line.\n",
        "\n",
        "Consider now the following extension of the model. Let preferences be heterogeneous and decomposed as:\n",
        "\n",
        "$$ \\psi\\log(\\alpha_{n}) = \\mu_{\\alpha} + \\varepsilon_{n},\\ \\mathbb{E}[\\varepsilon] = 0 $$\n",
        "\n",
        "and assume that hours are observed with additive measurement error ($\\xi_{n,t}$), such that:\n",
        "\n",
        "$$ \\log(H_{n,t}) = \\mu_{\\alpha} + \\psi\\log(W_{n,t}) + \\varepsilon_{n} + \\xi_{n,t}.$$\n",
        "\n",
        "For wages, likewise assume that:\n",
        "\n",
        "$$\\log(W_{n,t}) = \\gamma_{0} + Z_{n,t}\\gamma_{1} + \\zeta_{n} + \\upsilon_{n,t} $$\n",
        "\n",
        "where $\\zeta_{n}$ reflects an unobserved permanent component of $n$'s productivity and $\\nu_{n,t}$ is a time-varying shock. $Z_{n,t}$ is a variable that we think ought to shift labor demand in ways that are essentially random with respect to individual-level unobservables.\n",
        "\n",
        "\n",
        ":::{.callout-note}\n",
        "\n",
        "When you extend a model in this way (to account for randomness in outcomes), you should keep two things in mind:\n",
        "\n",
        "1. What is *my* theory for why this residual exists? As in: what is the structural error term in my model?\n",
        "2. What other components could explain part of this residual that are *not* in my model?\n",
        "\n",
        "Accordingly when you think about identification, you have two important tasks (in order of importance):\n",
        "\n",
        "1. Craft an argument and approach to identification that is  consistent with the assumptions of your model. Your model may already pose important enodgenity problems to solve.\n",
        "2. Craft an argument and approach to identification that is plausible and robust to potential mechanisms (members of the residual) that are *not* in your model.\n",
        "\n",
        "If you don't have (1), then there's no point in moving on to (2), but addressing (2) goes a long way to convincing your audience.\n",
        ":::\n",
        "\n",
        "## Simple Identification\n",
        "\n",
        "The simplest approach to identification would be to assume that the unobservables are simply independent of each other:\n",
        "\n",
        "$$ (\\varepsilon_{n}, \\xi_{n,t}) \\perp (\\zeta_{n},\\upsilon_{n,t}) $$\n",
        "\n",
        "This modeling assumption would imply that \n",
        "\n",
        "$$ \\mathbb{E}[\\varepsilon_{n}+\\xi_{n,t}|W_{n,t}] = 0 $$\n",
        "\n",
        "which is sufficient for OLS to consistently recover $\\psi$. This would mean we could estimate $\\psi$ with a single cross-section of wages and hours by simply regressing log hours on log wages.\n",
        "\n",
        "Returning to our discussion above, given these assumptions:\n",
        "\n",
        "1. It is easy to make an identification argument that is consistent *inside* the model.\n",
        "2. The modeling assumptions themselves are much harder to justify (think in terms of modeled and unmodeled unobservables).\n",
        "\n",
        ":::{.callout-warning icon=\"false\"}\n",
        "## Discussion\n",
        "Below is code to plot average log hours against log wages using our [CPS data](../appendices/data.qmd)."
      ],
      "id": "51afdddc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CSV, DataFrames, DataFramesMeta, Statistics, Binscatters, Plots\n",
        "\n",
        "data = CSV.read(\"../data/cps_00019.csv\",DataFrame)\n",
        "data = @chain data begin\n",
        "    @subset :EMPSTAT.<21\n",
        "    @transform @byrow :wage = begin\n",
        "        if :PAIDHOUR==0\n",
        "            return missing\n",
        "        elseif :PAIDHOUR==2\n",
        "            if :HOURWAGE<99.99 && :HOURWAGE>0\n",
        "                return :HOURWAGE\n",
        "            else\n",
        "                return missing\n",
        "            end\n",
        "        elseif :PAIDHOUR==1\n",
        "            if :EARNWEEK>0 && :UHRSWORKT<997 && :UHRSWORKT>0\n",
        "                return :EARNWEEK / :UHRSWORKT\n",
        "            else\n",
        "                return missing\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "    @subset :MONTH.==1\n",
        "    @select :AGE :SEX :RACE :EDUC :wage :UHRSWORKT\n",
        "    @subset .!ismissing.(:wage) :UHRSWORKT.<997 :UHRSWORKT.>0\n",
        "    @transform :log_wage = log.(:wage) :log_hours = log.(:UHRSWORKT)\n",
        "    binscatter(_, @formula(log_hours ~ log_wage))\n",
        "end"
      ],
      "id": "d02cf959",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Think of all the reasons why wages vary across people\n",
        "- Think of all the reasons why hours vary across individuals\n",
        "- Recall that $\\psi$ is a *causal* parameter. Is there anything even remotely plausible about the assumption that the unobserved determinants of wages are uncorrelated with unobserved determinants of hours?\n",
        "\n",
        ":::\n",
        "\n",
        "## Identification with Instrumental Variables\n",
        "\n",
        "In the simple (naive) approach above, by running OLS, our key identification condition was:\n",
        "\n",
        "$$ \\mathbb{E}[\\varepsilon + \\xi | W] = 0$$\n",
        "\n",
        "which implicitly assumed that *all* of the variation that goes into $W$ ($Z$, $\\upsilon$, and $\\zeta$) is essentially random (and therefore valid).\n",
        "\n",
        "The instrumental variables approach instead extracts the \"plausibly random\" component of wages given by the instrument, and requires instead that:\n",
        "\n",
        "$$ \\mathbb{E}[\\varepsilon + \\xi | Z] = 0 $$\n",
        "\n",
        "which, depending on the nature of $Z$, can be a much easier assumption to believe and defend. So when people say that this approach is more *credible*, what they mean is that the required assumptions for identification are weaker, easier to defend, and robust to the kinds of mechanisms that discredited the OLS approach.\n",
        "\n",
        ":::{.callout-tip icon=\"false\"}\n",
        "## Exercise\n",
        "\n",
        ":::{#exr-labor_supply_2SLS}\n",
        "Recall that the population estimand of 2SLS for one endogenous variable and one instrument is:\n",
        "\n",
        "$$ \\alpha_{2SLS} = \\frac{\\mathbb{C}(\\log(H),Z)}{\\mathbb{C}(\\log(W),Z)} $$\n",
        "\n",
        "Show that when $\\mathbb{E}[\\varepsilon + \\xi | Z]=0$ and $\\gamma_1\\neq0$, we get:\n",
        "\n",
        "$$ \\alpha_{2SLS} = \\psi $$\n",
        ":::\n",
        ":::\n",
        "\n",
        ":::{.callout-important icon=\"false\"}\n",
        "## Whether vs How\n",
        "\n",
        "Note that in this case, proving sufficient conditions for identification in either case is very straightforward.  This is the \"whether\". They are usually taken as given without further discussion. The \"how\" is more interesting, because it refers more to the *nature* of the respective independence assumptions. Note how the independence condition for IV is strictly weaker than the condition for OLS, and may (depending on $Z$) be much easier to defend *a priori*. \n",
        "\n",
        "**An additional key point is this**: sometimes out of necessity, we write simple models of supply and demand that imply that a naive identification strategy is valid *inside the model*. For example, in heterogeneous agent macro models, it is common to assume a homogeneous set of preferences, implying no unobserved heterogeneity in labor supply. If the model generated the data, we could consistently recover labor supply elasticities with OLS. Here, you have to *think outside the model* and ask whether that identification stategy is robust to mild extensions or mechanisms in the data that were too complicated for your model.\n",
        ":::\n",
        "\n",
        "<!-- :::{.callout-note}\n",
        "## Unobserved Heterogeneity\n",
        "Another important point is that **unobserved heterogeneity** is the key\n",
        "::: -->\n",
        "\n",
        "## Identification of the Model with Income Effects\n",
        "\n",
        "To simplify our discussion so far, we have assumed away income effects. From this point, let's once again assume $\\sigma>0$ and think about how this might complicate inference when using instrumental variables. Labor supply becomes:\n",
        "\n",
        "$$ \\log(H_{n,t}) = \\mu_{\\alpha} + \\psi\\log(W_{n,t}) - \\sigma\\psi\\log(C_{n,t}) + \\varepsilon_{n} + \\xi_{n,t}.$$\n",
        "\n",
        "Suppose that we now have access to one cross-section, giving the joint distribution $\\mathbb{P}_{Z,W,H,A,C}$ where $A$ is assets.\n",
        "\n",
        ":::{.callout-tip icon=\"false\"}\n",
        "## Exercise\n",
        ":::{#exr-labor_supply_IV}\n",
        "Suppose that $Z_{n,t}$ is a binary policy variable (let's say a tax credit) that is correctly perceived as permanent and is effectively randomly assigned. In this case you can assume that $W$ is the wage *net of taxes*.\n",
        "\n",
        "1. Consider the result of estimating the following system by 2SLS:\n",
        "$$\\log(H) = \\beta_0 + \\beta_1\\log(W) + \\epsilon_0 $$\n",
        "$$\\log(W) = \\kappa_0 + \\kappa_1Z + \\epsilon_1 $$\n",
        "Since $Z\\in\\{0,1\\}$, recall that the 2SLS estimand is:\n",
        "$$ \\alpha_{2SLS} = \\frac{\\mathbb{E}[\\log(H)|Z=1] - \\mathbb{E}[\\log(H)|Z=0]}{\\mathbb{E}[\\log(W)|Z=1] - \\mathbb{E}[\\log(W)|Z=0]} $$ \n",
        "Does $\\alpha_{2SLS}$ identify a structural parameter of interest in this case? Hint: you should be able to write $\\alpha_{2SLS}$ in terms of structural parameters and $\\mathbb{E}[\\log(C)|Z=1]-\\mathbb{E}[\\log(C)|Z=0]$.\n",
        "\n",
        "2. What very specific research question of interest does this 2SLS parameter identify?\n",
        "\n",
        "3. Recall that the rank conditions for IV suggest that we need two instruments given that we have two endogenous variables. Define $\\tilde{Z} = M\\times Z$ where $M\\in\\{0,1\\}$ is an indicator for whether $A$ is above or below the median. Note that the conditional expectation of log consumption can be written *wlog* as:\n",
        "$$ \\mathbb{E}[\\log(C)|M,Z] = \\delta_{0} + \\delta_{1}M + \\delta_{2}Z + \\delta_{3}\\underbrace{MZ}_{=\\tilde{Z}}$$\n",
        "**Use the model to argue** that $\\delta_{3}\\neq0$.\n",
        "\n",
        "4. Now show that one can write:\n",
        "$$ \\mathbb{E}[\\log(H)|M,Z] = \\kappa_{0} + \\kappa_{1}M + \\psi\\gamma_{1} Z - \\psi\\sigma \\delta_{2}Z - \\psi\\sigma \\delta_{3}\\tilde{Z}.$$\n",
        "And combine these two expressions with the wage equation to argue that $\\psi$ and $\\sigma$ are identified. Why is important that $\\delta_{3}\\neq 0$?\n",
        "\n",
        "5. Now we're going to write code to estimate the structural parameters with 2SLS and use a monte-carlo simulation to evaluate the performance of the estimator. The code below uses the same approach as in our [description of the model](../models/dynamic-labor-supply.qmd) and does almost everything for you! You just have to write one line to finish calculating the 2SLS estimate in each monte-carlo trial and output the results.\n"
      ],
      "id": "c439defa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# this function solves for consumption given constant wages\n",
        "function solve_consumption(r,α,W,A,σ,ψ)\n",
        "    Q = 1/ (1 - 1/(1+r))\n",
        "    f(c) = (Q * c - Q * W^(1 + ψ) * α^ψ * c^(-σ*ψ) - A)^2\n",
        "    r = Optim.optimize(f,0.,A+W)\n",
        "    return r.minimizer\n",
        "end\n",
        "# this function simulates the data\n",
        "function simulate_data(σ,ψ,r,γ,N)\n",
        "    ch = [0.3 0. 0.; 0.5 0.5 0.; 0.4 0.8 1.8]\n",
        "    Σ = ch * ch'\n",
        "    X = rand(MvNormal(Σ),N)\n",
        "    Z = rand(N) .< 0.5\n",
        "    α = exp.(X[1,:])\n",
        "    W = exp.(X[2,:])\n",
        "    W_net = exp.(Z .* γ) .* W\n",
        "    A = exp.(X[3,:])\n",
        "    C = [solve_consumption(r,α[i],W_net[i],A[i],σ,ψ) for i in eachindex(A)]\n",
        "    @views H = exp.( X[1,:] .+ ψ .* log.(W_net) .- σ * ψ .* log.(C) )\n",
        "    return (;α,W,A,C,H,W_net,Z)\n",
        "end\n",
        "\n",
        "# assume risk-aversion of 2 and frisch of 0.5\n",
        "σ = 2.\n",
        "ψ = 0.5\n",
        "r = 0.05\n",
        "γ = 0.2\n",
        "\n",
        "N = 10_000\n",
        "\n",
        "# here we run a the monte-carlo using 500 trials\n",
        "ψ_est = zeros(500)\n",
        "ψ_ols = zeros(500)\n",
        "for b in 1:500\n",
        "    dat = simulate_data(σ,ψ,r,γ,N)\n",
        "    #M = dat.A .< quantile(dat.A,0.75)\n",
        "    M = dat.A .< median(dat.A)\n",
        "    # construct instruments:\n",
        "    Z = [ones(N) M dat.Z dat.Z .* M]\n",
        "    X = [ones(N) M log.(dat.W_net) log.(dat.C)]\n",
        "    # first stage:\n",
        "    δ = inv(Z' * Z) * Z'*X\n",
        "    Xh = Z * δ\n",
        "    # ----- YOU HAVE TO FILL IN THE LINE HERE\n",
        "    # second stage:\n",
        "    β = ## <- WRITE THE FORMULA TO GET THE 2SLS ESTIMATE\n",
        "    # -------------------------------------- #\n",
        "    ψ_est[b] = β[3]\n",
        "    X = [ones(N) log.(dat.W_net) log.(dat.C)]\n",
        "    β_ols = inv(X' * X) * X' * log.(dat.H)\n",
        "    ψ_ols[b] = β_ols[2]\n",
        "end\n",
        "# this will plot the distribution relative to the OLS estimate\n",
        "histogram(ψ_est,alpha=0.4)\n",
        "histogram!(ψ_ols,alpha=0.4)\n",
        "xlims!((-2,2))"
      ],
      "id": "265d49e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        ":::{.callout-note icon=\"false\"}\n",
        "## Example: Difference in Differences\n",
        ":::{#exm-labor_supply_dd}\n",
        "Suppose that we have a two cross-sections of data $(H,W,Z,G)$ from two periods $t\\in\\{1,2\\}$ where $G\\in\\{A,B\\}$ indicates membership in one of two demographic groups. In this setting, let $Z\\in\\{0,1\\}$ indicate the presence of a proportional tax subsidy, $\\tau$, and that only group $B$ is eligible for the subsidy. Accordingly, assume that net wages follow:\n",
        "\n",
        "$$\\mathbb{E}[\\log(W)|G,t] = \\gamma_{t} + \\log(1+\\tau)Z_{t}\\mathbf{1}\\{G=B\\} + \\omega_{B}\\mathbf{1}\\{G=B\\}$$\n",
        "\n",
        "The parameter $\\omega_{B}$ captures persistent differences in labor market productivity between groups $A$ and $B$ and $\\gamma_{t}$ captures aggregate trends.\n",
        "\n",
        "The model also gives us:\n",
        "\n",
        "$$\\mathbb{E}[\\log(H)|G,t] = \\mu + \\kappa_{B}\\mathbf{1}\\{G=N\\} + \\psi\\mathbb{E}[\\log(W)|G,t] - \\psi\\sigma\\mathbb{E}[\\log(C)|G,t] $$\n",
        "\n",
        "Let $\\Delta$ indicate changes from period to period. Recall that the euler equation implies that, under full information and no shocks:\n",
        "\n",
        "$$ \\Delta\\mathbb{E}[\\log(C)|G] = \\log(\\beta(1+r))$$\n",
        "\n",
        "This means that *if the policy were never introduced*, we would also get:\n",
        "\n",
        "$$ \\Delta\\mathbb{E}[\\log(H)|G] = \\psi(\\gamma_{2}-\\gamma_{1})$$\n",
        "\n",
        "Thus we know that the **parallel trends assumption holds** for both log hours and log consumption. Suppose the policy is introduced **unexpectedly** in period 2. Parallel trends suggests that we could learn about the effect of this policy on hours. Recall that the difference-in-differences estimand is:\n",
        "\n",
        "$$ \\alpha^{H}_{DD} =  \\Delta\\mathbb{E}[\\log(H)|B] - \\Delta\\mathbb{E}[\\log(H)|A] $$\n",
        "\n",
        "Substituting terms gives\n",
        "\n",
        "$$ \\alpha^{H}_{DD} = \\psi\\log(1+\\tau) - \\sigma\\psi\\alpha^{C}_{DD} .$$\n",
        "\n",
        "where $\\alpha^C_{DD}$ is the effect of the policy on log consumption, which also happens to be the effect of the policy on the group B's log consumption.\n",
        "\n",
        "Some observations from this exercise:\n",
        "\n",
        "1. $\\alpha^{H}_{DD}$ identifies a very specific causal parameter: the effect of an unannounced policy introduction on hours for group B.\n",
        "2. If we had data on consumption and hours, we could combine $\\alpha^{C}_{DD}$ and $\\alpha^{H}_{DD}$ to learn $\\psi$ and $\\sigma$.\n",
        "3. To the extend that group A and B differ in the their preferences, wages, and assets, the policy is likely to have a different effect on their consumption. This heterogeneity income effects means that neither $\\alpha^{C}_{DD}$ nor $\\alpha^{C},\\alpha^{H}_{DD}$ combined identify the effect of the exact same tax subsidy on group A.\n",
        "4. These estimands also do not identify the effect of the policy on group $B$ when there is a different perceived persistence of the policy.\n",
        "5. If the policy was announced in period 1 and implemented in period 2, then the *parallel trends assumption would be violated*.\n",
        "6. We are able to achieve identification here withou assuming that $Z$ is independent of observables, but rather by noting and exploiting the existence of parallel trends.\n",
        "\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!-- do we use the diff-in-diff example? put this exercise in here?? -->\n",
        "\n",
        "## Identification with Panel Data\n",
        "\n",
        "Suppose now that we have **panel data** on hours and wages for each individual. We now see the population distribution $\\mathbb{P}_{(H_t,W_t,C_t)_{t=1}^{T}}$ for some $T$ periods of data. Taking first differences gives:\n",
        "\n",
        "$$ \\Delta\\log(H) = \\psi\\Delta\\log(W) - \\psi\\sigma\\Delta\\log(C) + \\Delta \\xi_{n,t} $$\n",
        "\n",
        "Notice that we can now identify $\\psi$ and $\\sigma$ under the assumption that\n",
        "\n",
        "$$ \\mathbb{E}[\\Delta \\xi_{n,t}|\\Delta\\log(W),\\Delta\\log(C)] =  0$$\n",
        "\n",
        "which guarantees that the OLS estimand from regression the change in log hours on the change in log wages and log consumption would recover $\\psi$ and $\\psi\\sigma$.\n",
        "\n",
        ":::{.callout-warning icon=\"false\"}\n",
        "## Panel vs Instrumental Approaches\n",
        "\n",
        "This example introduces a fairly consistent theme for solving identification problems in economics. Since unobserved heterogeneity lies at the heart of causal inference problems, one can typically find good solutions either by finding variation that is plausibly random (IV) or by using repeated observations to learn about and handle the unobserved variation. Later in this text we will cover some more advanced results on the panel data approach, which reaches much further than the simpled fixed effects approach in this example.\n",
        "\n",
        ":::\n",
        "\n",
        "Here are six additional comments on this panel data example:\n",
        "\n",
        "1. Much like the IV example, this approach essentially extracts a \"more credible\" source of variation in wages, using changes from year to year and differencing out permanent differences across individuals.\n",
        "2. Thinking *inside* the model, since $\\xi$ is assumed to be iid measurement error, this identification approach is valid.  \n",
        "3. What about outside it? Are there mechanisms outside the model that are likely to confound identification? One view is that this approach involves assumptions that are weaker than using OLS in the cross-section, but stronger than using a good instrument.\n",
        "4. If there is also measurement error in wages, the cure could be worse than the disease, since it could be driving most of the variation in wages from one period to the next.\n",
        "\n",
        ":::{.callout-important icon=\"false\"}\n",
        "## Whether vs How\n",
        "\n",
        "Note that, much like the IV strategy above, this panel data approach will consistently recover the parameters of interest regardless of whether unobserved heterogeneity is an issue or not. Thus, one could consider using this approach even if the plan is to use these parameters inside a simpler model of supply without unobserved heterogeneity.\n",
        "\n",
        ":::\n"
      ],
      "id": "535933a5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.11",
      "language": "julia",
      "display_name": "Julia 1.11.3",
      "path": "/Users/mullinsj/Library/Jupyter/kernels/julia-1.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}