[
  {
    "objectID": "lectures/extremum_intro_examples.html",
    "href": "lectures/extremum_intro_examples.html",
    "title": "12  Introducing the Estimators with Examples",
    "section": "",
    "text": "12.1 The Generalized Roy Model\nBefore diving into statistical theory, we will introduce the estimators by proposing estimation methods for each of our prototype models.\nThe three workhorse methods are:\nEach of these approaches is an extremum estimator: any estimator that can be characterized as the solution to a maximization or minimization problem.\nJust to clarify where we are going, it helps to reiterate what the key properties are that we would like to establish for each approach.\nTo discuss estimation of this model, let’s assume a linear form for the selection and outcomes equations:\n\\[ D = \\mathbf{1}\\{\\gamma_0 + \\gamma_1X + \\gamma_2Z - V \\geq0\\} \\] \\[ Y_{D} = \\beta_{D,0} + \\beta_{D,1}X + U_D \\] with \\(V\\sim\\mathcal{N}(0,1)\\).\nOur identification argument suggested a two-step estimator for the Generalized Roy Model, which we implemented in Example 7.1:\nNote that this is a two-step estimator. The second stage relies on parameters estimated in the first stage. We will need to develop theory for this!",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#the-generalized-roy-model",
    "href": "lectures/extremum_intro_examples.html#the-generalized-roy-model",
    "title": "12  Introducing the Estimators with Examples",
    "section": "",
    "text": "Estimate the selection equation by maximum likelihood: \\[ \\hat{\\gamma} = \\arg\\max_{\\gamma}\\frac{1}{N}\\sum_{n=1}^{N}D_{n}\\log(\\Phi(\\mathbf{w}_{n}\\gamma)) + (1-D_n)\\log(1-\\Phi(\\mathbf{w}_{n}\\gamma)) \\] where \\(\\mathbf{w}_{n} = [1,\\ X_{n},\\ Z_{n}]\\).\nEstimate the outcome equations with OLS using a selection correction.",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#the-search-model",
    "href": "lectures/extremum_intro_examples.html#the-search-model",
    "title": "12  Introducing the Estimators with Examples",
    "section": "12.2 The Search Model",
    "text": "12.2 The Search Model\nFor this example, let’s assume that we observe wages with some small amount of known measurement error:\n\\[ \\log(W^{o}_{n,t}) = \\log(W_{n,t}) + \\zeta_{n,t}\\]\nwhere \\(\\zeta_{n,t} \\sim \\mathcal{N}(0,\\sigma^2_\\zeta)\\) and \\(\\sigma_\\zeta = 0.05\\).\nRecall that without further variation, we must make a parametric assumption on the wage distribution, and so we assume that \\(W\\) is log-normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2_{W}\\).\nOur strategy here is to estimate the parameters\n\\[ \\theta = (\\mu,\\sigma^2_{W},h,\\delta,w^*) \\]\nand invert out \\(\\lambda\\) and \\(b\\) (the latter using the reservation wage equation). Let \\(X_{n} = (W^o,t_u,E)\\) indicate the data. The log-likelihood of a single observation is:\n\\[ l(X;\\theta) = E \\times \\int f_{W|W&gt;w^*}(\\log(W^{o})-\\zeta)\\phi(\\zeta;\\sigma_\\zeta)d\\zeta + (1-E)\\times[\\log(h) + t_u\\log(1-h)]  \\]\nwhere, according to our parametric specifications:\n\\[ f_{W|W&gt;w^*}(w) = \\frac{\\phi(w;\\sigma_{W})}{1-\\Phi(w^*/\\sigma_{W})}.\\]\n\\(\\phi(\\cdot;\\sigma)\\) is the pdf of a normal with standard deviation \\(\\sigma\\) and \\(\\Phi\\) is the cdf of a standard normal.\nThe maximum likelihood estimator is:\n\\[ \\hat{\\theta} = \\arg\\max_\\theta \\frac{1}{N}\\sum_{n}l(X_n;\\theta) \\] while the MLE estimates of \\(\\lambda\\) and \\(b\\) are:\n\\[ \\hat{\\lambda} = \\hat{h} / (1 - \\widehat{F}_{W|W&gt;w^*}(\\hat{w}^*) \\]\n\\[ \\hat{b} = w^* - \\frac{\\hat{\\lambda}}{1 - \\beta(1-\\hat{\\delta})}\\int_{\\hat{w}^*}(1-\\widehat{F}_{W|W&gt;w^*}(w))dw \\]\nWhen we get to the theory we will consider the asymptotic properties of not just \\(\\hat{\\theta}\\) but also the derived estimates \\(\\hat{b}\\) and \\(\\hat{\\lambda}\\).\n\n\n\n\n\n\nExample: Coding the Log-Likelihood\n\n\n\n\nExample 12.1 First, let’s load the routines that we previously wrote to solve the model and take numerical integrals with quadrature. These are identical to what we’ve seen before and are available on the course github.\n\ninclude(\"../scripts/search_model.jl\")\n\nsolve_res_wage (generic function with 1 method)\n\n\nBefore writing the likelihood, let’s load the data, clean, and create the data frame.\n\nusing CSV, DataFrames, DataFramesMeta, Statistics\n\ndata = CSV.read(\"../data/cps_00019.csv\",DataFrame)\ndata = @chain data begin\n    @transform :E = :EMPSTAT.&lt;21\n    @transform @byrow :wage = begin\n        if :PAIDHOUR==0\n            return missing\n        elseif :PAIDHOUR==2\n            if :HOURWAGE&lt;99.99 && :HOURWAGE&gt;0\n                return :HOURWAGE\n            else\n                return missing\n            end\n        elseif :PAIDHOUR==1\n            if :EARNWEEK&gt;0 && :UHRSWORKT&lt;997 && :UHRSWORKT&gt;0\n                return :EARNWEEK / :UHRSWORKT\n            else\n                return missing\n            end\n        end\n    end\n    @subset :MONTH.==1\n    @select :AGE :SEX :RACE :EDUC :wage :E :DURUNEMP\n    @transform begin\n        :bachelors = :EDUC.&gt;=111\n        :nonwhite = :RACE.!=100 \n        :female = :SEX.==2\n        :DURUNEMP = round.(:DURUNEMP .* 12/52)\n    end\nend\n\n# the whole dataset in a named tuple\nwage_missing = ismissing.(data.wage)\nwage = coalesce.(data.wage,1.)\nN = length(data.AGE)\n# create a named tuple with all variables to conveniently pass to the log-likelihood:\ndat = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP) \n\n(logwage = [0.0, 0.0, 0.0, 3.0368742168851663, 2.302585092994046, 3.2188758248682006, 2.2512917986064953, 0.0, 0.0, 0.0  …  0.0, 0.0, 2.4849066497880004, 3.056356895370426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], wage_missing = Bool[1, 1, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 0, 1, 1, 1, 1, 1, 1], E = Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], tU = [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0  …  231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0])\n\n\nNow, let’s write the log-likelihood as above.\n\nusing Distributions, Optim\n\nϕ(x,μ,σ) = pdf(Normal(μ,σ),x)\nΦ(x,μ,σ) = cdf(Normal(μ,σ),x)\n\n# a function for the log-likelihood of observed wages (integrating out measurement error)\nfunction logwage_likelihood(logwage,F,σζ,wres)\n    f(x) = pdf(F,x) / (1-cdf(F,wres)) * ϕ(logwage,log(x),σζ)\n    ub = quantile(F,0.9999)\n    return integrateGL(f,wres,ub)\nend\n\n# a function to get the log-likelihood of a single observation\n# note this function assumes that data holds vectors \n# E, tU, and logwage\nfunction log_likelihood(n,data,pars)\n    (;h,δ,wres,F,σζ) = pars\n    ll = 0.\n    if data.E[n]\n        ll += log(h) - log(h + δ)\n        if !data.wage_missing[n]\n            ll += logwage_likelihood(data.logwage[n],F,σζ,wres)\n        end\n    else\n        ll += log(δ) - log(h + δ)\n        ll += log(h) + data.tU[n] * log(1-h)\n    end\n    return ll\nend\n\n# a function to iterate over all observations\nfunction log_likelihood_obj(x,pars,data)\n    pars = update(pars,x)\n    ll = 0.\n    for n in eachindex(data.E)\n        ll += log_likelihood(n,data,pars)\n    end\n    return ll / length(data.E)\nend\n\nlog_likelihood_obj (generic function with 1 method)\n\n\nFinally, since routines like Optim optimize over vectors, we want to write an update routine that takes a vector x and maps it to new parameters. Here we are going to use transformation functions to ensure that parameters obey their bound constraints. There are other ways to ensure this, but this is one way that works.\n\nlogit(x) = exp(x) / (1+exp(x))\nlogit_inv(x) = log(x/(1-x))\n\nfunction update(pars,x)\n    h = logit(x[1])\n    δ = logit(x[2])\n    μ = x[3]\n    σ = exp(x[4])\n    wres = exp(x[5])\n    F = LogNormal(μ,σ)\n    return (;pars...,h,δ,μ,σ,wres,F)\nend\n\nupdate (generic function with 1 method)\n\n\nNow we can finally test our likelihood to see how it runs:\n\nx0 = [logit_inv(0.5),logit_inv(0.03),2.,log(1.),log(5.)]\npars = (;σζ = 0.05, β = 0.995)\nlog_likelihood_obj(x0,pars,dat) #&lt;- test.\nres = optimize(x-&gt;-log_likelihood_obj(x,pars,dat),x0,Newton(),Optim.Options(show_trace=true))\n\nIter     Function value   Gradient norm \n     0     2.428210e-01     2.348428e-01\n * time: 5.984306335449219e-5\n     1     2.051862e-01     1.072566e-01\n * time: 1.8515889644622803\n     2     1.827395e-01     4.626301e-01\n * time: 3.292236804962158\n     3     1.758193e-01     4.441528e-01\n * time: 4.586717844009399\n     4     1.692587e-01     3.168138e-02\n * time: 6.080646991729736\n     5     1.668869e-01     1.483080e-01\n * time: 7.363166809082031\n     6     1.647839e-01     2.507384e-01\n * time: 8.843937873840332\n     7     1.638445e-01     1.648957e-01\n * time: 10.333063840866089\n     8     1.633820e-01     2.338710e-02\n * time: 11.627697944641113\n     9     1.633356e-01     2.095668e-02\n * time: 13.11549687385559\n    10     1.633224e-01     1.774668e-03\n * time: 14.597818851470947\n    11     1.633213e-01     3.628638e-03\n * time: 16.073489904403687\n    12     1.633211e-01     1.280346e-04\n * time: 17.559399843215942\n    13     1.633210e-01     3.719531e-04\n * time: 19.04760980606079\n    14     1.633210e-01     5.299485e-06\n * time: 20.525203943252563\n    15     1.633210e-01     3.008006e-05\n * time: 22.201759815216064\n    16     1.633210e-01     8.243085e-08\n * time: 23.69115400314331\n    17     1.633210e-01     6.359010e-08\n * time: 24.976842880249023\n    18     1.633210e-01     2.488281e-07\n * time: 26.455304861068726\n    19     1.633210e-01     2.588340e-08\n * time: 27.74436092376709\n    20     1.633210e-01     1.472700e-08\n * time: 29.030247926712036\n    21     1.633210e-01     2.956400e-09\n * time: 30.599798917770386\n\n\n * Status: success (objective increased between iterations)\n\n * Candidate solution\n    Final objective value:     1.633210e-01\n\n * Found with\n    Algorithm:     Newton's Method\n\n * Convergence measures\n    |x - x'|               = 6.08e-06 ≰ 0.0e+00\n    |x - x'|/|x'|          = 2.83e-07 ≰ 0.0e+00\n    |f(x) - f(x')|         = 1.60e-13 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 9.82e-13 ≰ 0.0e+00\n    |g(x)|                 = 2.96e-09 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   31  (vs limit Inf)\n    Iterations:    21\n    f(x) calls:    66\n    ∇f(x) calls:   66\n    ∇²f(x) calls:  21\n\n\nHere we tell Optim to make use of automatic differentiation with ForwardDiff. Let’s take a peek at the parameter estimates:\n\nDataFrame(;update(pars,res.minimizer)...)\n\n1×8 DataFrame\n\n\n\nRow\nσζ\nβ\nh\nδ\nμ\nσ\nwres\nF\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nLogNorma…\n\n\n\n\n1\n0.05\n0.995\n0.184915\n0.00764741\n3.47993\n1.09258\n4.80711e-10\nLogNormal{Float64}(μ=3.47993, σ=1.09258)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance Note\n\n\n\nNote that in Example 12.1 we created a NamedTuple called dat from the data frame, which cements the type of each vector of data into dat.\nThis is important for performance! Working with DataFrame types directly can dramatically slow down your code because the columns of these data frames are not typed concretely. See the performance tips for more discussion.\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nExercise 12.1 Extend the code above to\n\nAdditionally estimate the parameters \\(b\\) and \\(\\lambda\\).\nEstimate the search model separately for men with and without a bachelor’s degree.\nReport and comment on your estimates.",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#the-labor-supply-model",
    "href": "lectures/extremum_intro_examples.html#the-labor-supply-model",
    "title": "12  Introducing the Estimators with Examples",
    "section": "12.3 The Labor Supply Model",
    "text": "12.3 The Labor Supply Model\nSuppose that we have a vector of instruments \\(\\mathbf{z}_{n}\\) that we hope will jointly move consumption and labor supply, with a single cross-section of observations:\n\\[ (W_{n},H_{n},C_{n},\\mathbf{z}_{n}).\\]\nWe write the labor supply equation as\n\\[ \\log(H) = \\mu - \\psi\\log(W) - \\psi\\sigma\\log(C) + \\epsilon \\]\nwhere we assume that \\(\\mathbb{E}[\\epsilon\\ |\\mathbf{z}] = 0\\), implying the moment condition:\n\\[ \\mathbb{E}[\\epsilon \\mathbf{z}] = 0.\\]\nLet \\(\\theta  = (\\mu,\\sigma,\\psi)\\) and define the sample moment:\n\\[g_{N}(\\theta) = \\frac{1}{N}\\sum_{N}\\left(\\log(H_{n})-\\mu-\\psi\\log(W)-\\psi\\sigma\\log(C)\\right)\\mathbf{z}_{n}.\\]\nThe GMM estimator is:\n\\[ \\hat{\\theta} = \\arg\\min_{\\theta} g_{N}(\\theta)^\\prime \\mathbf{W}_{N} g_{N}(\\theta) \\]\nwhere \\(\\mathbf{W}_{N}\\) is a symmetric, positive definite weighting matrix. Since we have a linear system, this becomes a quadratic minimization problem with a known solution,1 but the theory we develop will be more general.\nRelevant questions for GMM are:\n\nWhat value of \\(\\mathbf{W}\\) will give us the “best” performing estimator in the population? (And yes, we also have to define what “best” means).\nCan we implement optimal weighting in finite sample?",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#the-savings-model",
    "href": "lectures/extremum_intro_examples.html#the-savings-model",
    "title": "12  Introducing the Estimators with Examples",
    "section": "12.4 The Savings Model",
    "text": "12.4 The Savings Model\nLet’s consider estimation of the income process for this model and save estimation of the preference parameters for our chapter on simulation. Recall from our discussion of identification and from Exercise 10.1 that we can identify the parameters of this process by matching implied variances and covariances. Supposing that we have more of these moments than we do parameters (i.e. that the parameters are over-identified by the moments), we can estimate the income process by minimum distance.\nRecall the income process: \\[ \\varepsilon_{n,t+1} = \\rho \\varepsilon_{n,t} + \\eta_{n,t},\\qquad \\eta_{n,t}\\sim\\mathcal{N}(0,\\sigma^2_\\eta) \\]\nand consider the extended specification with permanent heterogeneity: \\[ \\log(y_{n,t}) = \\mu_t + \\alpha_n + \\varepsilon_{n,t} \\]\nwhere \\(\\alpha_n \\sim (0,\\sigma^2_\\alpha)\\) is an individual fixed effect. Let us further assume that in the first period, \\(\\varepsilon_{0} = 0\\). This gives us that\n\\[\\varepsilon_{t} = \\sum_{s=1}^{t}\\rho^{t-s}\\eta_{s}.\\]\nDefine \\(\\theta = (\\rho, \\sigma^2_\\alpha, \\sigma^2_\\eta)\\) as the parameters we wish to estimate.\n\n12.4.1 The Minimum Distance Estimator\nIn Example 10.1, we considered identification of the income process by examining covariance restrictions in panel data. Here we’ll consider this approach as well as an alternative. Define\n\\[\\epsilon = \\log(y) - \\mu_{t} = \\alpha + \\varepsilon \\]\nLet’s begin by noting the following generic relationships:\n\\[ \\mathbb{V}[\\epsilon_{t}] = \\sigma^2_{\\alpha} + \\frac{(1-\\rho^{2(t-1)})}{1-\\rho^2}\\sigma^2_{\\eta}\\]\nand\n\\[ \\mathbb{V}[\\epsilon_{t+1}] = \\sigma^2_{\\alpha} + \\rho^2\\mathbb{V}[\\varepsilon_{t}] + \\sigma^2_{\\eta} \\]\n\\[ \\mathbb{C}(\\epsilon_{t},\\epsilon_{t+s}) = \\sigma^2_{\\alpha} + \\rho^{s}\\mathbb{V}[\\epsilon_{t}] \\]\nWe’ll consider two potential vectors of moments to match. The first vector consists of the variance of \\(\\epsilon\\) at each \\(t\\):\n\\[ \\mathbf{v} = [\\mathbb{V}[\\epsilon_{1}],\\ \\mathbb{V}[\\epsilon_{2}],\\ ...,\\ \\mathbb{V}[\\epsilon_{T}]]^\\prime \\]\nwhile the second takes two variances and \\(K\\) covariances:\n\\[\\mathbf{c} = [\\mathbb{V}[\\epsilon_{t}],\\ \\mathbb{V}[\\epsilon_{t+1}],\\ \\mathbb{C}(\\epsilon_{t},\\epsilon_{t+1}),\\ ...,\\ \\mathbb{C}(\\epsilon_{t},\\epsilon_{t+K})]^\\prime \\]\nLet \\(\\mathbf{v}(\\theta)\\) and \\(\\mathbf{c}(\\theta)\\) be the model-implied values of these moments, given by the expressions above. The minimum distance estimator is\n\\[ \\hat{\\theta} = \\arg\\min_\\theta \\left(\\hat{\\mathbf{v}} - \\mathbf{v}(\\theta)\\right)^\\prime \\mathbf{W} \\left(\\hat{\\mathbf{v}} - \\mathbf{v}(\\theta)\\right) \\]\nwhere \\(\\mathbf{W}\\) is a positive definite weighting matrix. An estimator is equivalently defined for the second set of moments \\(\\mathbf{c}\\).\n\n\n\n\n\n\nExample: Minimum Distance Estimation of the Income Process\n\n\n\n\nExample 12.2 Building on Example 10.1, let’s implement a minimum distance estimator for the income process parameters. First, we compute sample moments from the PSID data.\n\nusing CSV, DataFrames, DataFramesMeta, Statistics, Optim, Plots\n\n# Load and prepare data\ndata = @chain begin\n    CSV.read(\"../data/abb_aea_data.csv\",DataFrame,missingstring = \"NA\")\n    @select :person :y :tot_assets1 :asset :age :year\n    @subset :age.&gt;=25 :age.&lt;=64\nend\n\n# Calculate the variance of log income at each age\nm_hat = @chain data begin\n    groupby(:age)\n    @combine :var_logy = var(log.(:y))\n    @orderby :age\n    _.var_logy\nend\n\n40-element Vector{Float64}:\n 0.2832928560329017\n 0.31385672611280657\n 0.3481614098261801\n 0.49042885748190596\n 0.7186945866590636\n 0.8145871761041581\n 0.3899819595842863\n 0.4310734870614536\n 1.0048586189529876\n 0.8330684076119356\n 0.6927461795744777\n 0.4530783605245448\n 0.7647115466410289\n ⋮\n 0.7856911636904547\n 0.8002257744890358\n 0.6119942670835942\n 0.9594333073919417\n 0.6036241679859082\n 1.0296983130781643\n 0.6008575915783718\n 1.1495148217769573\n 0.7851363933479678\n 1.6514958037883842\n 0.5559690181469094\n 1.1855708905092428\n\n\nNow we define the model-implied moments. Since PSID is biennial, we adjust for two-year gaps:\n\nfunction model_moments(θ, T)\n    ρ, σ2_α, σ2_η = θ\n    # Variance of transitory component (assuming stationarity for simplicity)\n    var_eps = σ2_η / (1 - ρ^2)\n    m = [σ2_α + (1-ρ^(2(t-1)))/(1-ρ^2) * σ2_η for t in 1:T]\n    return m\nend\n\n# Minimum distance objective (identity weighting matrix)\nfunction md_objective(x, m_hat)\n    # Transform to ensure constraints: ρ ∈ (-1,1), σ² &gt; 0\n    ρ = tanh(x[1])\n    σ2_α = exp(x[2])\n    σ2_η = exp(x[3])\n    θ = (ρ, σ2_α, σ2_η)\n    T = length(m_hat)\n    m_model = model_moments(θ, T)\n    diff = m_hat .- m_model\n    return diff' * diff  # Identity weighting\nend\n\nmd_objective (generic function with 1 method)\n\n\nFinally, we estimate the parameters:\n\n# Initial values\nx0 = [0.5, log(0.1), log(0.05)]\n\n# Optimize\nres = optimize(x -&gt; md_objective(x, m_hat), x0, Newton(),autodiff = :forward)\n\n# Extract estimates\nx_hat = res.minimizer\nρ_hat = tanh(x_hat[1])\nσ2_α_hat = exp(x_hat[2])\nσ2_η_hat = exp(x_hat[3])\nθ_hat = (ρ_hat, σ2_α_hat, σ2_η_hat)\nprintln(\"Minimum Distance Estimates:\")\nprintln(\"  ρ = $(round(ρ_hat, digits=3))\")\nprintln(\"  σ²_α = $(round(σ2_α_hat, digits=3))\")\nprintln(\"  σ²_η = $(round(σ2_η_hat, digits=3))\")\n# and finally a plot of model fit\nT = length(m_hat)\nscatter(1:T,m_hat,label = \"data\",title = \"Model Fit of Targeted Moments\")\nplot!(1:T,model_moments(θ_hat,length(m_hat)),label = \"model fit\")\nxlabel!(\"Model Periods (Age)\")\n\nMinimum Distance Estimates:\n  ρ = 0.918\n  σ²_α = 0.279\n  σ²_η = 0.085\n\n\n\n\n\n\n\n\nAs with the case of GMM, we would like to know how our choice of \\(\\mathbf{W}\\) affects the sampling distribution (i.e. precision) of our estimator and if there is an “optimal” choice.\n\n\n\n\n\n\nDiscussion: Whether vs How\n\n\n\nLet’s think about more about how we approached identification here: by matching the growth in the variance of log income with age.\nEssentially, we are attributing all of this growth to income risk. Suppose we use the model to evaluate the welfare gains from redistributive taxes and transfers. Are you comfortable with how we’ve identified the extent of income risk? How important will those parameters be for how agents value social insurance?",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#the-entry-exit-model",
    "href": "lectures/extremum_intro_examples.html#the-entry-exit-model",
    "title": "12  Introducing the Estimators with Examples",
    "section": "12.5 The Entry-Exit Model",
    "text": "12.5 The Entry-Exit Model\nConsider two alternative estimators of the entry-exit model. The key insight from our identification discussion is that the choice probability \\(p(x,a,a')\\) is directly observable in the data and encodes information about the underlying payoff parameters.\nRecall the payoff specification: \\[ u_{1}(x,a,d^{\\prime}) = \\phi_{0} + \\phi_{1}x - \\phi_{2}d^\\prime - \\phi_{3}(1-a) \\] \\[ u_{0}(x,a) = \\phi_{4}a \\]\nand let \\(\\phi = (\\phi_0, \\phi_1, \\phi_2, \\phi_3, \\phi_4)\\) denote the vector of payoff parameters.\n\n12.5.1 Estimation by Minimum Distance\nThe minimum distance approach directly exploits the mapping between parameters and choice probabilities. For each market-state combination \\((x,a,a')\\), the model implies a choice probability:\n\\[ p(x,a,a';\\phi,\\beta) = \\frac{\\exp(v_1(x,a,a';\\phi,\\beta))}{\\exp(v_0(x,a,a';\\phi,\\beta)) + \\exp(v_1(x,a,a';\\phi,\\beta))} \\]\nwhere \\(v_0\\) and \\(v_1\\) are the choice-specific value functions that depend on the equilibrium solution.\nSuppose we have a cross-section of data:\n\\[ (X_{m},D_{m},A_{m},A'_{m})_{m=1}^{M} \\]\nfor each of \\(M\\) markets. Further assume that \\(X\\) is a variable that takes one of a discrete number of values in the support \\(\\mathcal{X}\\).\nFor each unique state \\((x,a,a')\\) in the data, we can compute the empirical choice frequency:\n\\[ \\hat{p}(x,a,a') = \\frac{\\sum_{m} D_{m}\\mathbf{1}\\{X_m = x, A_{m} = a, A'_{m} = a'\\}}{\\sum_{m} \\mathbf{1}\\{X_m = x, A_{m} = a, A'_{m} = a'\\}} \\]\nThe minimum distance estimator minimizes the weighted sum of squared deviations between observed and predicted choice probabilities. Let \\(\\mathbf{p}(\\theta)\\) be the vector of choice probabilities across the state space \\(\\mathcal{X}\\times\\{0,1\\}^2\\) and let \\(\\widehat{\\mathbf{p}}\\) be the equivalent frequency estimate. The minimum distance estimator is:\n\\[ \\hat{\\theta} = \\arg\\min_\\theta (\\widehat{\\mathbf{p}}-\\mathbf{p}(\\theta))^\\prime \\mathbf{W}_{N}(\\widehat{\\mathbf{p}}-\\mathbf{p}(\\theta))\\]\nwhere \\(\\mathbf{W}_{N}\\) is once again a positive definite weighting matrix.\n\n\n12.5.2 Estimation by GMM\nAn alternative approach uses the Generalized Method of Moments. The key insight is that choice probabilities satisfy certain orthogonality conditions that can be expressed as moment restrictions.\nGiven the discrete choice structure, the residual: \\[ \\xi_{m} = D_{m} - p(X_m, A_{m}, A'_{m}; \\phi, \\beta) \\]\nhas the property that \\(\\mathbb{E}[\\xi_{m} | X_m, A_{m}, A'_{m}] = 0\\) when evaluated at the true parameters. This suggests the moment conditions:\n\\[ \\mathbb{E}\\left[(D_{m} - p(X_m, A_{m}, A'_{m}; \\phi, \\beta)) \\cdot \\mathbf{z}_{m}\\right] = 0 \\]\nwhere \\(\\mathbf{z}_{m}\\) is a vector of instruments. Natural choices include functions of \\((X_m, A_{m}, A'_{m})\\) themselves, such as:\n\\[ \\mathbf{z}_{m} = [1,\\ X_m,\\ A_{m},\\ A'_{m},\\ X_m \\cdot A_{m}]^\\prime \\]\nThe GMM estimator minimizes:\n\\[ \\hat{\\phi} = \\arg\\min_\\phi g_M(\\phi)^\\prime \\mathbf{W}_M g_M(\\phi) \\]\nwhere the sample moment is:\n\\[ g_M(\\phi) = \\frac{1}{M}\\sum_{m}\\left(D_{m} - p(X_m, A_{m}, A'_{m}; \\phi, \\beta)\\right) \\mathbf{z}_{m} \\]",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "lectures/extremum_intro_examples.html#footnotes",
    "href": "lectures/extremum_intro_examples.html#footnotes",
    "title": "12  Introducing the Estimators with Examples",
    "section": "",
    "text": "Specifically, let \\(\\beta = [\\mu,\\ \\psi, \\psi\\sigma]^\\prime\\), we know that: \\(\\hat{\\beta} = (\\mathbf{X}^\\prime\\mathbf{Z}\\mathbf{W}_{N}\\mathbf{Z}^\\prime\\mathbf{X})^{-1}(\\mathbf{X}^\\prime\\mathbf{Z}\\mathbf{W}_{N}\\mathbf{Z}^\\prime\\mathbf{Y}\\) where \\(\\mathbf{X}\\), \\(\\mathbf{Z}\\), \\(\\mathbf{Y}\\) are appropriately stacked vectors of regressors, instruments, and outcomes (log hours).↩︎",
    "crumbs": [
      "Extremum Estimators",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introducing the Estimators with Examples</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aguirregabiria, Victor, and Pedro Mira. 2002. “Swapping the Nested\nFixed Point Algorithm: A Class of Estimators for Discrete Markov\nDecision Models.” Econometrica 70 (4): 1519–43.\n\n\n———. 2007. “Sequential Estimation of Dynamic Discrete\nGames.” Econometrica 75 (1): 1–53.\n\n\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2010. “The\nCredibility Revolution in Empirical Economics: How Better Research\nDesign Is Taking the Con Out of Econometrics.” Journal of\nEconomic Perspectives 24 (2).\n\n\nArellano, Manuel, Richard Blundell, and Stephane Bonhomme. 2018.\n“Nonlinear Persistence and Partial Insurance: Income and\nConsumption Dynamics in the PSID.” AEA Papers and\nProceedings 108 (May): 281–86. https://doi.org/10.1257/pandp.20181049.\n\n\nBlundell, Richard, and Ian Walker. 1986. “A Life-Cycle Consistent\nEmpirical Model of Family Labour Supply Using Cross-Section\nData.” The Review of Economic Studies 53 (4): 539–58.\n\n\nCarneiro, P., J. J. Heckman, and E. J. Vytlacil. 2011. “Estimating\nMarginal Returns to Education.” American Economic Review\n101 (October): 2754–81. http://www.nber.org/papers/w16474.\n\n\nChernozhukov, Victor, and Christian Hansen. 2005. “An IV Model of\nQuantile Treatment Effects.” Econometrica 73 (1):\n245–61.\n\n\nChesher, Andrew. 2010. “Instrumental Variable Models for Discrete\nOutcomes.” Econometrica 78 (2): 575–601.\n\n\nCunha, Flavio, James Heckman, and Susanne Schennach. 2010.\n“Estimating the Technology of Cognitive and Noncognitive Skill\nFormation.” Econometrica 78 (3): 883–931.\n\n\nDe Nardi, Mariacristina. 2004. “Wealth Inequality and\nIntergenerational Links.” The Review of Economic Studies\n71 (3): 743–68. https://doi.org/10.1111/j.1467-937X.2004.00302.x.\n\n\nDearing, Adam, and Jason R. Blevins. 2024. “Efficient and\nConvergent Sequential Pseudo-Likelihood Estimation of Dynamic Discrete\nGames.” Review of Economic Studies.\n\n\nEricson, Richard, and Ariel Pakes. 1995. “Markov-Perfect Industry\nDynamics: A Framework for Empirical Work.” The Review of\nEconomic Studies 62 (1): 53–82. https://doi.org/10.2307/2297841.\n\n\nFlinn, Christopher, and James Heckman. 1982. “New Methods for\nAnalyzing Structural Models of Labor Force Dynamics.” Journal\nof Econometrics 18 (1): 115–68.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with\nVariation in Treatment Timing.” Journal of Econometrics\n225 (2): 254–77. https://doi.org/https://doi.org/10.1016/j.jeconom.2021.03.014.\n\n\nGorman, W. M. 1959. “Separable Utility and Aggregation.”\nEconometrica 27 (3): 469–81. http://www.jstor.org/stable/1909472.\n\n\nGourinchas, Pierre-Olivier, and Jonathan A. Parker. 2002.\n“Consumption over the Life Cycle.” Econometrica 70\n(1): 47–89. https://doi.org/10.1111/1468-0262.00269.\n\n\nHarberger, Arnold C. 1954. “Monopoly and Resource\nAllocation.” The American Economic Review 44 (2): 77–87.\nhttp://www.jstor.org/stable/1818325.\n\n\nHeckman, James J, and Bo E Honore. 1990. “The Empirical Content of\nthe Roy Model.” Econometrica: Journal of the Econometric\nSociety, 1121–49.\n\n\nHeckman, James, and Burton Singer. 1984. “A Method for Minimizing\nthe Impact of Distributional Assumptions in Econometric Models for\nDuration Data.” Econometrica: Journal of the Econometric\nSociety, 271–320.\n\n\nHeckman, James, and Edward Vytlacil. 2005. “Structural equations, treatment effects, and econometric\npolicy evaluation.” Econometrica 73 (3): 669–738.\n\n\n———. 2007. “Chapter 70 Econometric Evaluation of Social Programs,\nPart i: Causal Models, Structural Models and Econometric Policy\nEvaluation.” In, edited by James J. Heckman and Edward E. Leamer,\n6:4779–874. Handbook of Econometrics. Elsevier. https://doi.org/https://doi.org/10.1016/S1573-4412(07)06070-9.\n\n\nImbens, Guido W., and Joshua D. Angrist. 1994. “Identification and\nEstimation of Local Average Treatment Effects.”\nEconometrica 62 (2): 467–75. http://www.jstor.org/stable/2951620.\n\n\nKasahara, Hiroyuki, and Katsumi Shimotsu. 2009. “Nonparametric\nIdentification of Finite Mixture Models of Dynamic Discrete\nChoices.” Econometrica 77 (1): 135–75.\n\n\nKleven, Henrik J. 2021. “Sufficient Statistics Revisited.”\nJournal Article. Annual Review of Economics 13 (Volume 13,\n2021): 515–38. https://doi.org/https://doi.org/10.1146/annurev-economics-060220-023547.\n\n\nLewbel, Arthur. 2019. “The Identification Zoo: Meanings of\nIdentification in Econometrics.” Journal of Economic\nLiterature 57 (4): 835–903. https://doi.org/10.1257/jel.20181361.\n\n\nLucas Jr, Robert E. 1976. “Econometric Policy Evaluation: A\nCritique.” In Carnegie-Rochester Conference Series on Public\nPolicy, 1:19–46. North-Holland.\n\n\nMaCurdy, Thomas E. 1981. “An Empirical Model of Labor Supply in a\nLife-Cycle Setting.” Journal of Political Economy 89\n(6): 1059–85.\n\n\nMagnac, Thierry, and David Thesmar. 2002. “Identifying Dynamic\nDiscrete Decision Processes.” Econometrica 70 (2):\n801–16. https://doi.org/https://doi.org/10.1111/1468-0262.00306.\n\n\nMarschak, Jacob. 1953. “Economic Measurements for Policy and\nPrediction.” In Studies in Econometric Method, edited by\nW. Hood and C. Koopmans. John Wiley & Sons.\n\n\nMcCall, John Joseph. 1970. “Economics of Information and Job\nSearch.” The Quarterly Journal of Economics 84 (1):\n113–26.\n\n\nMullins, Joseph. 2026. “A Structural Meta-Analysis of Welfare\nReform Experiments and Their Impacts on Children.” Journal of\nPolitical Economy 134 (1): 435–77. https://doi.org/10.1086/738482.\n\n\nRoy, A. D. 1951. “Some Thoughts on the Distribution of\nEarnings.” Oxford Economic Papers 3 (2): 135–46. http://www.jstor.org/stable/2662082.\n\n\nVytlacil, Edward J. 2002. “Independence ,\nMonotonicity and Latent Index Models : An Equivalence\nResult.” Econometrica 70 (1): 331–41.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "appendices/data.html",
    "href": "appendices/data.html",
    "title": "Appendix A — Data",
    "section": "",
    "text": "A.1 A Disclaimer for IPUMS CPS data\nThese data are a subsample of the IPUMS CPS data available from cps.ipums.org. Any use of these data should be cited as follows:\nSarah Flood, Miriam King, Renae Rodgers, Steven Ruggles, J. Robert Warren, Daniel Backman, Annie Chen, Grace Cooper, Stephanie Richards, Megan Schouweiler, and Michael Westberry. IPUMS CPS: Version 11.0 [dataset]. Minneapolis, MN: IPUMS, 2023. https://doi.org/10.18128/D030.V11.0\nThe CPS data file is intended only for exercises as part of ECON8208. Individuals are not to redistribute the data without permission. Contact ipums@umn.edu for redistribution requests. For all other uses of these data, please access data directly via cps.ipums.org.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "appendices/data.html#a-disclaimer-for-ipums-cps-data",
    "href": "appendices/data.html#a-disclaimer-for-ipums-cps-data",
    "title": "Appendix A — Data",
    "section": "",
    "text": "Arellano, Manuel, Richard Blundell, and Stephane Bonhomme. 2018. “Nonlinear Persistence and Partial Insurance: Income and Consumption Dynamics in the PSID.” AEA Papers and Proceedings 108 (May): 281–86. https://doi.org/10.1257/pandp.20181049.\n\n\nDearing, Adam, and Jason R. Blevins. 2024. “Efficient and Convergent Sequential Pseudo-Likelihood Estimation of Dynamic Discrete Games.” Review of Economic Studies.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html",
    "href": "appendices/autodiff.html",
    "title": "Appendix B — Automatic Differentiation",
    "section": "",
    "text": "B.1 Why AD Matters for Structural Estimation\nIn structural econometrics, we frequently need gradients for:\nHand-coding derivatives is tedious and error-prone. Finite differences are slow (requiring \\(O(n)\\) function evaluations for an \\(n\\)-dimensional gradient) and can be numerically unstable. AD provides exact gradients efficiently.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#why-ad-matters-for-structural-estimation",
    "href": "appendices/autodiff.html#why-ad-matters-for-structural-estimation",
    "title": "Appendix B — Automatic Differentiation",
    "section": "",
    "text": "Optimization (MLE, GMM, minimum distance)\n\nGradient-free methods such as Nelder-Mead are popular, of course, but are less efficient\n\nComputing standard errors\nSolving models with equilibrium conditions (using Newton’s method, for example)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#forward-mode-vs-reverse-mode",
    "href": "appendices/autodiff.html#forward-mode-vs-reverse-mode",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.2 Forward Mode vs Reverse Mode",
    "text": "B.2 Forward Mode vs Reverse Mode\nAD comes in two flavors:\nForward mode propagates derivatives forward through the computation. For a function \\(f: \\mathbb{R}^n \\to \\mathbb{R}^m\\), computing the full Jacobian requires \\(n\\) forward passes. This is efficient when \\(n \\ll m\\).\nReverse mode propagates derivatives backward (like backpropagation in neural networks). Computing the full Jacobian requires \\(m\\) reverse passes. This is efficient when \\(m \\ll n\\).\nFor most estimation problems, we have a scalar objective (\\(m = 1\\)) and many parameters (\\(n\\) large), so reverse mode is typically preferred. In my experience however, I have had more success writing code that is compatible with forward differencing. You will learn from experience that these tools can be fussy.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#ad-in-julia",
    "href": "appendices/autodiff.html#ad-in-julia",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.3 AD in Julia",
    "text": "B.3 AD in Julia\nJulia’s AD ecosystem is excellent. The main packages are:\n\nB.3.1 ForwardDiff.jl\nForward-mode AD. Simple and robust, works out-of-the-box for most pure Julia code.\n\nusing ForwardDiff\n\nf(x) = sum(x.^2)\nx = [1.0, 2.0, 3.0]\n\n# Gradient\nForwardDiff.gradient(f, x)\n\n3-element Vector{Float64}:\n 2.0\n 4.0\n 6.0\n\n\n\n# Hessian\nForwardDiff.hessian(f, x)\n\n3×3 Matrix{Float64}:\n 2.0  0.0  0.0\n 0.0  2.0  0.0\n 0.0  0.0  2.0\n\n\n\n\nB.3.2 Enzyme.jl\nA high-performance AD engine that works at the LLVM level. Supports both forward and reverse mode. Often the fastest option, especially for code with loops and mutations.\n\nusing Enzyme\n\nf(x) = x[1]^2 + sin(x[2])\n\nx = [1.0, 2.0]\ndx = zeros(2)\n\n# Reverse mode gradient\nEnzyme.autodiff(Reverse, f, Active, Duplicated(x, dx))\ndx\n\n2-element Vector{Float64}:\n  2.0\n -0.4161468365471424\n\n\n\n\nB.3.3 Zygote.jl\nA source-to-source reverse-mode AD system. Popular in machine learning (used by Flux.jl). Works well for array-heavy code but may struggle with control flow.\n\nusing Zygote\n\nf(x) = sum(x.^2)\nx = [1.0, 2.0, 3.0]\n\nZygote.gradient(f, x)\n\n([2.0, 4.0, 6.0],)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#practical-recommendations",
    "href": "appendices/autodiff.html#practical-recommendations",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.4 Practical Recommendations",
    "text": "B.4 Practical Recommendations\n\nStart with ForwardDiff for problems with few parameters (&lt; 100). It’s the most reliable.\nUse Enzyme for performance-critical code, especially if you have loops or in-place mutations.\nBe aware of limitations: AD systems can fail on code that uses certain constructs (try-catch, foreign function calls, some global variables). When in doubt, test that your gradients match finite differences:\n\n\nusing ForwardDiff, FiniteDiff\n\nf(x) = log(1 + exp(x[1] * x[2])) + x[3]^2\nx = [1.0, 2.0, 3.0]\n\nad_grad = ForwardDiff.gradient(f, x)\nfd_grad = FiniteDiff.finite_difference_gradient(f, x)\n\nmaximum(abs.(ad_grad .- fd_grad))\n\n5.3512749786932545e-12",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#integration-with-optimization",
    "href": "appendices/autodiff.html#integration-with-optimization",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.5 Integration with Optimization",
    "text": "B.5 Integration with Optimization\nMost Julia optimization packages accept AD gradients. Here’s an example with Optim.jl:\n\nusing Optim, ForwardDiff\n\nrosenbrock(x) = (1 - x[1])^2 + 100*(x[2] - x[1]^2)^2\nx0 = [0.0, 0.0]\n\n# With automatic gradients via ForwardDiff\nresult = optimize(rosenbrock, x0, LBFGS(); autodiff = :forward)\nresult.minimizer\n\n2-element Vector{Float64}:\n 0.999999999999928\n 0.9999999999998559",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#example-maximum-likelihood-with-optim.jl",
    "href": "appendices/autodiff.html#example-maximum-likelihood-with-optim.jl",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.6 Example: Maximum Likelihood with Optim.jl",
    "text": "B.6 Example: Maximum Likelihood with Optim.jl\nConsider a simple probit model:\n\\[ D = \\mathbf{1}\\{X\\beta - \\nu \\geq 0\\},\\qquad \\nu \\sim \\mathcal{N}(0,1) \\]\nHere is code to simulate data for this model:\n\nusing Random, Distributions\n\nfunction sim_data(X ; γ)\n    N = size(X,1)\n    ν = rand(Normal(),N)\n    D = (X * γ .- ν) .&gt; 0\n    return D\nend\n\n# a quick test of the function:\nN = 1000\nX = [ones(N) 2*rand(Normal(),N)]\nγ = [0.1, 0.5]\nD = sim_data(X ; γ);\n\nConsider the problem of estimating \\(\\gamma\\) using maximum likelihood. We will establish the properties of this estimator in class. Here let’s just focus on numerically how to attack the minimization problem. The log-likelihood of the data D given X is:\n\\[ \\mathcal{L}(\\gamma) = \\sum_{n}l(D_{n}; X_{n},\\gamma) = \\sum_{n=1}^{N}D_{n}\\log(\\Phi(X\\gamma)) + (1-D_{n})\\log(1-\\Phi(X\\gamma)) \\]\nLet’s write up this likelihood function.\n\nfunction log_likelihood(D,X,γ)\n    ll = 0.\n    for n in eachindex(D)\n        xg = X[n,1] * γ[1] + X[n,2] * γ[2] \n        if D[n]\n            ll += log(cdf(Normal(),xg))\n        else\n            ll += log(1-cdf(Normal(),xg))\n        end\n    end\n    return ll\nend\nlog_likelihood(D,X,[0.,0.])\n\n-693.1471805599322\n\n\n\nB.6.1 Numerical Optimization\nOptimization is most efficient when we have access to the first and second order derivatives of the function. There is a general class of hill-climbing (or descent in the case of minimization) algorithms that find new guesses \\(\\gamma_{k+1}\\) given \\(\\gamma_{k}\\) as:\n\\[ \\gamma_{k+1} = \\gamma_{k} + \\lambda_{k}A_{k}\\frac{\\partial Q}{\\partial \\gamma} \\]\nwhere \\(Q\\) is the function being maximized (or minimized). \\(A_{k}\\) defines a direction in which to search (providing weights on the derivatives) and \\(\\lambda_{k}\\) is a scalar variable known as a step-size which is often calculated optimally in each iteration \\(k\\). For Newton’s method, the matrix \\(A_{k}\\) is the inverse of the Hessian of the objective function \\(Q\\). Since the hessian can sometimes be expensive to calculate, other methods use approximations to the Hessian that are cheaper to compute.\nSince we have a simple model, we can calculate derivatives relatively easily. Below we’ll compare a hard-coded derivative to this automatic differentiation.\n\nusing ForwardDiff\n\nfunction deriv_ll(D,X,γ)\n    dll = zeros(2)\n    for n in eachindex(D)\n        xg = X[n,1] * γ[1] + X[n,2] * γ[2] \n        if D[n]\n            dl = pdf(Normal(),xg) / cdf(Normal(),xg)\n        else\n            dl = - pdf(Normal(),xg) / (1 - cdf(Normal(),xg))\n        end\n        dll[1] += X[n,1] * dl\n        dll[2] += X[n,2] * dl            \n    end\n    return dll\nend\ndx = zeros(2)\n# forward mode\nauto_deriv_ll(D,X,γ) = ForwardDiff.gradient(x-&gt;log_likelihood(D,X,x),γ)\n# reverse mode\nauto_deriv2_ll(D,X,γ,dx) = Enzyme.autodiff(Reverse, x-&gt;log_likelihood(D,X,x), Active, Duplicated(γ, dx))\n\nd1 = deriv_ll(D,X,γ)\nd2 = auto_deriv_ll(D,X,γ)\nauto_deriv2_ll(D,X,γ,dx)\n[d1 d2 dx]\n\n2×3 Matrix{Float64}:\n 18.585   18.585   18.585\n 36.7039  36.7039  36.7039\n\n\nOk so we’re confident that these functions work as intended, but how do they compare in performance?\n\n@time deriv_ll(D,X,γ);\n@time auto_deriv_ll(D,X,γ);\n@time auto_deriv2_ll(D,X,γ,dx);\n\n  0.000021 seconds (2 allocations: 80 bytes)\n  0.000035 seconds (7 allocations: 304 bytes)\n  0.000033 seconds\n\n\nAll are quite quick and you can see that we’re not losing much with automatic differentiation. In my experience, the gap between the two methods can narrow for more complicated functions.\nSo now let’s try implementing the maximum likelihood estimator using two different gradient-based algorithms: Newton’s Method (which uses the Hessian), and the Broyden–Fletcher–Goldfarb–Shannon (BFGS) algorithm (which updates search direction using changes in the first derivative).\nWhile Newton’s method requires calculation of the Hessian (second derivatives), BFGS and related methods only require first derivatives. Typically, this makes each iteration quicker but will take more time to converge. Let’s test them.\n\nusing Optim\nmin_objective(x) = -log_likelihood(D,X,x) #&lt;- Optim assumes that we will minimize a function, hence the negative\nγ_guess = zeros(2)\nprintln(\" ---- Using Newton's Method ------ \")\nres1 = optimize(min_objective,γ_guess,Newton(),autodiff=:forward,Optim.Options(show_trace=true))\nprintln(\" ---- Using BFGS ------ \")\nres2 = optimize(min_objective,γ_guess,BFGS(),autodiff=:forward,Optim.Options(show_trace=true))\n[res1.minimizer res2.minimizer γ]\n\n ---- Using Newton's Method ------ \nIter     Function value   Gradient norm \n     0     6.931472e+02     8.794794e+02\n * time: 0.011163949966430664\n     1     5.038529e+02     1.424353e+02\n * time: 0.3925299644470215\n     2     4.896962e+02     5.718137e+00\n * time: 0.39277005195617676\n     3     4.896776e+02     6.554352e-04\n * time: 0.39298009872436523\n     4     4.896776e+02     2.812263e-10\n * time: 0.3931429386138916\n ---- Using BFGS ------ \nIter     Function value   Gradient norm \n     0     6.931472e+02     8.794794e+02\n * time: 5.507469177246094e-5\n     1     5.022184e+02     1.277309e+02\n * time: 0.007002115249633789\n     2     4.993056e+02     1.210926e+02\n * time: 0.007193088531494141\n     3     4.898180e+02     1.538296e+01\n * time: 0.007416963577270508\n     4     4.896776e+02     7.292141e-02\n * time: 0.007581949234008789\n     5     4.896776e+02     2.642307e-03\n * time: 0.007750034332275391\n     6     4.896776e+02     6.079906e-08\n * time: 0.007950067520141602\n     7     4.896776e+02     3.867739e-14\n * time: 0.008134126663208008\n\n\n2×3 Matrix{Float64}:\n 0.143143  0.143143  0.1\n 0.540119  0.540119  0.5",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/autodiff.html#further-reading",
    "href": "appendices/autodiff.html#further-reading",
    "title": "Appendix B — Automatic Differentiation",
    "section": "B.7 Further Reading",
    "text": "B.7 Further Reading\n\nJuliaDiff documentation\nForwardDiff.jl docs\nEnzyme.jl docs",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Automatic Differentiation</span>"
    ]
  },
  {
    "objectID": "appendices/performance.html",
    "href": "appendices/performance.html",
    "title": "Appendix C — Performance Tips",
    "section": "",
    "text": "C.1 The Golden Rules",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Performance Tips</span>"
    ]
  },
  {
    "objectID": "appendices/performance.html#the-golden-rules",
    "href": "appendices/performance.html#the-golden-rules",
    "title": "Appendix C — Performance Tips",
    "section": "",
    "text": "C.1.1 1. Avoid Global Variables\nGlobal variables with non-constant types force the compiler to generate slow, generic code.\n# Bad\ndata = [1.0, 2.0, 3.0]\nf() = sum(data)  # `data` could change type\n\n# Good: use const\nconst DATA = [1.0, 2.0, 3.0]\nf() = sum(DATA)\n\n# Good: pass as argument\nf(data) = sum(data)\n\n\nC.1.2 2. Write Type-Stable Functions\nA function is type-stable if the output type can be inferred from the input types. Type instability forces runtime dispatch.\n# Bad: returns Int or Float64 depending on value\nfunction unstable(x)\n    if x &gt; 0\n        return 1\n    else\n        return 0.0\n    end\nend\n\n# Good: consistent return type\nfunction stable(x)\n    if x &gt; 0\n        return 1.0\n    else\n        return 0.0\n    end\nend\nUse @code_warntype to check for type instabilities (look for red Any or Union types).\n\n\nC.1.3 3. Pre-allocate Arrays\nAvoid creating arrays inside loops. Pre-allocate and use in-place operations.\n# Bad: allocates on every iteration\nfunction bad_example(n)\n    result = 0.0\n    for i in 1:n\n        v = zeros(100)  # allocation!\n        v .= rand(100)\n        result += sum(v)\n    end\n    result\nend\n\n# Good: pre-allocate\nfunction good_example(n)\n    result = 0.0\n    v = zeros(100)\n    for i in 1:n\n        rand!(v)  # in-place\n        result += sum(v)\n    end\n    result\nend\n\n\nC.1.4 4. Use @views for Array Slices\nArray slices create copies by default. Use @views or view() to avoid allocation.\nA = rand(1000, 1000)\n\n# Bad: creates a copy\nf(A[1:100, :])\n\n# Good: creates a view\nf(@views A[1:100, :])",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Performance Tips</span>"
    ]
  },
  {
    "objectID": "appendices/performance.html#quick-profiling",
    "href": "appendices/performance.html#quick-profiling",
    "title": "Appendix C — Performance Tips",
    "section": "C.2 Quick Profiling",
    "text": "C.2 Quick Profiling\nUse @time for basic timing (run twice—first call includes compilation):\n@time my_function(args)  # compile\n@time my_function(args)  # actual timing\nFor more detailed analysis: - BenchmarkTools.jl: Accurate microbenchmarks with @btime - Profile (stdlib): Sampling profiler - ProfileView.jl: Flame graph visualization",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Performance Tips</span>"
    ]
  },
  {
    "objectID": "appendices/performance.html#further-resources",
    "href": "appendices/performance.html#further-resources",
    "title": "Appendix C — Performance Tips",
    "section": "C.3 Further Resources",
    "text": "C.3 Further Resources\n\nJulia Performance Tips — the official guide, essential reading\nJulia Academy performance course — free video tutorials\nBenchmarkTools.jl documentation",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Performance Tips</span>"
    ]
  },
  {
    "objectID": "lectures/identification_savings.html",
    "href": "lectures/identification_savings.html",
    "title": "10  The Life-Cycle Savings Model",
    "section": "",
    "text": "10.1 Identification of the Income Process\nWe’ll consider identification of the savings model with the following income process:\n\\[ \\log(y_{n,t}) = \\mu_{t} + \\varepsilon_{n,t}\\]\nwhere\n\\[ \\varepsilon_{n,t+1} = \\rho \\varepsilon_{n,t} + \\eta_{n,t},\\qquad \\eta_{m,t}\\sim\\mathcal{N}(0,\\sigma^2_\\eta) \\].\nCollecting parameters, we want to identify\n\\[ (\\mu,\\rho,\\sigma_\\eta),\\qquad (\\beta,\\sigma,\\psi) \\]\nwhere the first block indicates parameters of the income process, and the second block determines preferences.\nAssume that our data has a panel dimension, so that we see \\((y_t,C_t,t)_{t=\\tau_0}^{\\tau_1}\\) for some pair \\((\\tau_0,\\tau_1)\\). Remember that \\(t\\) indexes age in the model, so it is quite plausible that \\(\\tau_0\\) and \\(\\tau_1\\) may themselves be random variables (this will be true in the data… we see panels of individuals at different ages and for different lengths of time).\nFirst, as long as the support of the random variables (\\(\\tau_0,\\tau_1\\)) covers \\(t=1\\) through to \\(T\\), \\(\\mu\\) is identified as the mean of log income at each age, \\(\\mu_t = \\mathbb{E}[\\log(y_{t})]\\). We can then residualize log income to get \\(\\varepsilon_{t} = \\log(y_t)-\\mu_t\\).\nSecond, consider the following variances and covariances (remember that the \\(\\eta\\) terms are iid):\n\\[\\begin{eqnarray}\n\\mathbb{V}[\\varepsilon_{t+1}] = \\rho^2\\mathbb{V}[\\varepsilon_{t}] + \\sigma^2_{\\eta} \\\\\n\\mathbb{C}(\\varepsilon_{t},\\varepsilon_{t+1}) = \\rho\\mathbb{V}[\\varepsilon_{t}] \\\\\n\\mathbb{C}(\\varepsilon_{t},\\varepsilon_{t+2}) = \\rho^2\\mathbb{V}[\\varepsilon_t]\n\\end{eqnarray}\\]\nmeaning that we can identify \\(\\rho\\) and \\(\\sigma_\\eta\\) from this system of simultaneous equations.",
    "crumbs": [
      "Identification and Credible Inference",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Life-Cycle Savings Model</span>"
    ]
  },
  {
    "objectID": "lectures/identification_savings.html#identification-of-the-income-process",
    "href": "lectures/identification_savings.html#identification-of-the-income-process",
    "title": "10  The Life-Cycle Savings Model",
    "section": "",
    "text": "Note: Whether vs How\n\n\n\nNote that, since these moments can be calculated at any age \\(t\\) and can extend to arbitrary lags, this model is over-identified. Which moments should we use in practice? Thinking inside the model, we will address this topic when we get to discussing minimum distance estimation. You might also like to think outside the model and think about (1) how real income processes might deviate from your stylized model and (2) what features of the data you most want the parameters \\(\\rho\\) and \\(\\sigma^2\\) to capture.\n\n\n\n\n\n\n\n\nExample: Data from PSID\n\n\n\n\nExample 10.1 In this example we’ll load psid data from Arellano, Blundell, and Bonhomme (2018) and show how sample equivalents to the above moments might be calculated.\nTo begin, let’s load the data and pull out the variables we are interested in using. These are person identifiers (person), year, total income (y), savings (tot_assets1) and age. You should bear in mind that it is by no means trivial to measure total income and total assets in these data. The variables we are looking at are the product of a lot of data cleaning and careful choices by the authors.\n\nusing CSV, DataFrames, DataFramesMeta, Statistics\ndata = @chain begin \n    CSV.read(\"../data/abb_aea_data.csv\",DataFrame,missingstring = \"NA\")\n    @select :person :y :tot_assets1 :asset :age :year\nend\n\n19317×6 DataFrame19292 rows omitted\n\n\n\nRow\nperson\ny\ntot_assets1\nasset\nage\nyear\n\n\n\nInt64\nInt64\nInt64\nFloat64\nInt64\nInt64\n\n\n\n\n1\n12061\n173100\n605000\n15500.0\n65\n98\n\n\n2\n17118\n54000\n60000\n0.0\n49\n98\n\n\n3\n12630\n61283\n224000\n39283.0\n59\n98\n\n\n4\n12647\n42300\n28240\n0.0\n38\n98\n\n\n5\n5239\n82275\n7500\n0.0\n56\n98\n\n\n6\n2671\n69501\n48000\n3600.0\n35\n98\n\n\n7\n13027\n68000\n148000\n20000.0\n49\n98\n\n\n8\n6791\n93758\n80000\n160.0\n41\n98\n\n\n9\n6475\n26581\n23300\n0.0\n35\n98\n\n\n10\n18332\n33785\n0\n0.0\n42\n98\n\n\n11\n3856\n55300\n311000\n5300.0\n33\n98\n\n\n12\n19326\n40200\n105250\n0.0\n40\n98\n\n\n13\n21818\n42500\n13000\n0.0\n36\n98\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n19306\n6617\n115887\n241000\n21346.0\n62\n108\n\n\n19307\n626\n128600\n98000\n0.0\n46\n108\n\n\n19308\n4795\n105000\n-68000\n0.0\n34\n108\n\n\n19309\n3223\n120000\n132000\n0.0\n47\n108\n\n\n19310\n8098\n26527\n4700\n0.0\n37\n108\n\n\n19311\n8954\n144026\n220000\n25.0\n46\n108\n\n\n19312\n12990\n122665\n220000\n0.0\n53\n108\n\n\n19313\n8782\n55000\n69000\n0.0\n31\n108\n\n\n19314\n13059\n42728\n-10000\n0.0\n26\n108\n\n\n19315\n13535\n57000\n0\n0.0\n26\n108\n\n\n19316\n3806\n87000\n74200\n0.0\n26\n108\n\n\n19317\n11085\n74000\n-50000\n0.0\n31\n108\n\n\n\n\n\n\nTo map to the model, assume that agents begin (\\(t=1\\)) when aged 25 and live for 40 years (so the “terminal” period is at age 64). Thus, we should filter the data to look at only these ages.\n\n@subset!(data,:age.&gt;=25,:age.&lt;=64);\n\nNow let’s residualize log wages by age, to get our estimate of \\(\\varepsilon_{n,t}\\):\n\ndata = @chain data begin\n    groupby(:age)\n    @transform :eps = log.(:y) .- mean(log.(:y))\nend;\n\nNext, here is a simple way of creating lagged variables (by mutating the year, renaming, and merging).\n\nd1 = @chain data begin\n    @select :year :person :eps\n    @transform :year = :year .- 2\n    @rename :epslag1 = :eps\nend\n\nd2 = @chain data begin\n    @select :year :person :eps\n    @transform :year = :year .- 4\n    @rename :epslag2 = :eps\nend\n\ndata = @chain data begin\n    innerjoin(d1 , on=[:person,:year])\n    innerjoin(d2 , on=[:person,:year])\nend;\n\nAn example of calculating covariances:\n\n@chain data begin\n    @combine begin \n        :c1 = cov(:eps,:epslag1) \n        :c2 = cov(:eps,:epslag2)\n    end\nend;\n\nSince the psid interviews are only every two years, we have to adjust our estimate of \\(\\rho\\) slightly by taking the square root of the covariance ratio:\n\nrho_est = sqrt(ans.c2[1] / ans.c1[1])\nprintln(\"The estimate of rho is $(round(rho_est,digits=2))\")\n\nThe estimate of rho is 0.98\n\n\nWhen it comes to the identification of this income process, let’s consider its ability to fit the life-cycle profile in the variance of income:\n\nusing Plots\nd = @chain begin data\n    groupby(:age)\n    @combine :var_income = var(log.(:y))\nend\nscatter(d.age,d.var_income,smooth = true,label = false)\n\n\n\n\nThe variance of log income seems to grow linearly with age, so this would be hard for our income process to fit if either\n\nWe assume that \\(\\varepsilon\\) is initially in its stationary distribution; or\n\\(\\rho\\) is far from 1, since it implies a concave path for the variance.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nExercise 10.1 Suppose that income processes also feature permanent differences in productivity among individuals, so that:\n\\[ \\log(y_{n,t}) = \\mu_t + \\alpha_n + \\varepsilon_{n,t} \\]\nwhere \\(\\varepsilon_{n,t}\\) is defined as before, and \\(\\alpha_n\\) is the individual fixed effect in wages. Assume that \\(\\alpha\\perp \\varepsilon_1\\), \\(\\alpha \\perp \\eta_t\\) for all \\(t\\), and define \\(\\sigma^2_\\alpha = \\mathbb{V}[\\alpha]\\).\n\nShow that you can identify this income process using additional covariances.\nEstimate the parameters \\((\\rho,\\sigma^2_\\alpha,\\sigma^2_\\eta)\\) by following your identification argument using the psid data from Example 10.1.\nHow do your estimates compare to Example 10.1 where we ignored permanent individual heterogeneity?",
    "crumbs": [
      "Identification and Credible Inference",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Life-Cycle Savings Model</span>"
    ]
  },
  {
    "objectID": "lectures/identification_savings.html#identification-of-preference-parameters",
    "href": "lectures/identification_savings.html#identification-of-preference-parameters",
    "title": "10  The Life-Cycle Savings Model",
    "section": "10.2 Identification of Preference Parameters",
    "text": "10.2 Identification of Preference Parameters\nThis is an interesting case because the problem will likely more closely reflect how you will approach identification in your own research.\nIn previous examples, we typically made use of analytical (i.e. “pencil and paper”) representations of optimal behavior as they relate to deeper parameters, and we used this for identification. That is harder to do here since we know we must solve for savings policies numerically.\n\n\n\n\n\n\nIdentification of more complicated models\n\n\n\nHere are some steps to help you think through identification of your model.\n\nCould you obtain identification if you had a “perfect” data set or experiment? Do your data allow a second-best approximation that harnesses the intuition of this perfect alternative? Remember that to show identification you can dispense with the practical considerations of finite samples and zoom in on very specific comparisons within the population distribution.\nWhat kind of variation is in the data that you do have and how do the parameters determine individuals’ response to that variation? If necessary, you can play with numerical solutions of the model to develop your intuition here.\nCan you simplify your model in a way that highlights some of the key forces of identification?\n\n\n\nThese approaches all differ in their level of precision. Your main goal is to provide your audience and yourself with some credible and sensible intuition. For the savings model, let’s use some combination of strategies (2) and (3). First, note that when \\(\\psi=0\\), individuals would run their assets down to zero in the final period. Thus, \\(\\psi\\) is very clearly identified by average bequests at the end of the life-cycle.\nNow, suppose we remove uncertainty from the model and impose the natural borrowing constraint, such that the Euler equation becomes:\n\\[ \\beta(1+r)\\left(\\frac{C_{t+1}}{C_{t}}\\right)^{-\\sigma}=1 \\]\nNotice that \\(\\sigma\\) determines the intertemporal elasticity of substitution: how individuals would substitute consumption across periods when there is variation in the price of doing so (\\(r\\)). What sources of variation do we have in this model? Only the income shocks \\(\\eta\\). Without uncertainty, individuals then choose a consumption profile based on the effect of that shock on the net present value of income. The resultant path depends on \\(\\beta\\), \\(r\\), and \\(\\sigma\\), but importantly \\(\\beta\\) and \\(\\sigma\\) are not separately identified. Thus, uncertainty and borrowing constraints hold the key for separately identifying parameters in our setting.\nNow, we know from experimenting with this model that as individuals accumulate assets, the risk of hitting the borrowing constraint diminishes and their behavior begins to more closely reflect the case without uncertainty: consumption responses are very close to linear with respect to cash in hand. Thus, to identify \\(\\beta\\) and \\(\\sigma\\) separately, we need to focus on potential nonlinearities in consumption behavior closer to the borrowing constraint. One example of a set of identifying moments would be:\n\nMean assets at each age; and\nThe covariance of changes in log consumption with log income conditional on different asset levels.\n\nWhile the first set of moments should pin down \\(\\beta\\) and \\(\\psi\\) jointly by effectively matching average consumption profiles, the second set attempts to pin down the nonlinear effect that \\(\\sigma\\) has on consumption at different wealth levels.\nAs you can see, this is a sensible intuitive approach to identification that does not offer an exact mapping between data and parameters.\nSince \\(\\sigma\\) determines both risk aversion and the intertemporal elasticity of substitution, some ideal data settings that would identify \\(\\sigma\\) would include:\n\nThe risk profile of asset portfolio choices (we don’t have this).\nVariation in the income risk faced by individuals (we don’t have this).\nVariation in the returns to saving either through \\(r_t\\) or through policy intervention (we don’t have this).\n\nIn general then there are many ways to identify \\(\\sigma\\), but most are missing in our simple model, so we will have to be more careful with the moments we choose.\n\n\n\n\n\n\nWhether vs How\n\n\n\nSuppose you wanted to use this model to evaluate the effect of a pension program reform on savings behavior. Would you be comfortable forecasting counterfactuals with this kind of identification approach? What kind of variation in the data would help you feel that your identification approach was more credible?\n\n\n\n\n\n\nArellano, Manuel, Richard Blundell, and Stephane Bonhomme. 2018. “Nonlinear Persistence and Partial Insurance: Income and Consumption Dynamics in the PSID.” AEA Papers and Proceedings 108 (May): 281–86. https://doi.org/10.1257/pandp.20181049.",
    "crumbs": [
      "Identification and Credible Inference",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Life-Cycle Savings Model</span>"
    ]
  }
]