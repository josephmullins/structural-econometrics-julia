<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>13&nbsp; Asymptotic Theory – Structural Econometrics with Julia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../lectures/simulation-methods.html" rel="next">
<link href="../lectures/extremum_intro_examples.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-626149efe8f5d16e1d391ba177679bf0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../lectures/extremum-estimators.html">Extremum Estimators</a></li><li class="breadcrumb-item"><a href="../lectures/extremum_theory.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Structural Econometrics with Julia</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Five Prototype Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/generalized_roy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Generalized Roy Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Job Search Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/savings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">A Life-Cycle Savings Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/entry-exit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Firm Entry-Exit Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/dynamic-labor-supply.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">A Simple Labor Supply Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/why_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">How and Why to Use Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../lectures/identification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Identification and Credible Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/identification_roy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Generalized Roy Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/identification_search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The Search Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/identification_labor_supply.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Dynamic Labor Supply Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/identification_savings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">The Life-Cycle Savings Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/identification_duopoly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">The Entry-Exit Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../lectures/extremum-estimators.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Extremum Estimators</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/extremum_intro_examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introducing the Estimators with Examples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/extremum_theory.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Simulation Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/simulation-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Simulation Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Discrete Choice</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Automatic Differentiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/performance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Performance Tips</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#definitions" id="toc-definitions" class="nav-link active" data-scroll-target="#definitions"><span class="header-section-number">13.1</span> Definitions</a>
  <ul class="collapse">
  <li><a href="#m-estimators" id="toc-m-estimators" class="nav-link" data-scroll-target="#m-estimators"><span class="header-section-number">13.1.1</span> M-estimators</a></li>
  <li><a href="#gmm-estimator" id="toc-gmm-estimator" class="nav-link" data-scroll-target="#gmm-estimator"><span class="header-section-number">13.1.2</span> GMM Estimator</a></li>
  <li><a href="#minimum-distance-estimator" id="toc-minimum-distance-estimator" class="nav-link" data-scroll-target="#minimum-distance-estimator"><span class="header-section-number">13.1.3</span> Minimum Distance Estimator</a></li>
  </ul></li>
  <li><a href="#consistency" id="toc-consistency" class="nav-link" data-scroll-target="#consistency"><span class="header-section-number">13.2</span> Consistency</a>
  <ul class="collapse">
  <li><a href="#uniform-convergence" id="toc-uniform-convergence" class="nav-link" data-scroll-target="#uniform-convergence"><span class="header-section-number">13.2.1</span> Uniform Convergence</a></li>
  <li><a href="#consistency-of-maximum-likelihood" id="toc-consistency-of-maximum-likelihood" class="nav-link" data-scroll-target="#consistency-of-maximum-likelihood"><span class="header-section-number">13.2.2</span> Consistency of Maximum Likelihood</a></li>
  </ul></li>
  <li><a href="#asymptotic-normality" id="toc-asymptotic-normality" class="nav-link" data-scroll-target="#asymptotic-normality"><span class="header-section-number">13.3</span> Asymptotic Normality</a>
  <ul class="collapse">
  <li><a href="#derivation-via-the-mean-value-theorem" id="toc-derivation-via-the-mean-value-theorem" class="nav-link" data-scroll-target="#derivation-via-the-mean-value-theorem"><span class="header-section-number">13.3.1</span> Derivation via the Mean Value Theorem</a></li>
  <li><a href="#the-information-matrix-equality" id="toc-the-information-matrix-equality" class="nav-link" data-scroll-target="#the-information-matrix-equality"><span class="header-section-number">13.3.2</span> The Information Matrix Equality</a></li>
  <li><a href="#the-delta-method" id="toc-the-delta-method" class="nav-link" data-scroll-target="#the-delta-method"><span class="header-section-number">13.3.3</span> The Delta Method</a></li>
  </ul></li>
  <li><a href="#efficiency" id="toc-efficiency" class="nav-link" data-scroll-target="#efficiency"><span class="header-section-number">13.4</span> Efficiency</a>
  <ul class="collapse">
  <li><a href="#efficiency-of-maximum-likelihood" id="toc-efficiency-of-maximum-likelihood" class="nav-link" data-scroll-target="#efficiency-of-maximum-likelihood"><span class="header-section-number">13.4.1</span> Efficiency of Maximum Likelihood</a></li>
  </ul></li>
  <li><a href="#minimum-distance-estimators" id="toc-minimum-distance-estimators" class="nav-link" data-scroll-target="#minimum-distance-estimators"><span class="header-section-number">13.5</span> Minimum Distance Estimators</a>
  <ul class="collapse">
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup"><span class="header-section-number">13.5.1</span> Setup</a></li>
  <li><a href="#asymptotic-distribution" id="toc-asymptotic-distribution" class="nav-link" data-scroll-target="#asymptotic-distribution"><span class="header-section-number">13.5.2</span> Asymptotic Distribution</a></li>
  <li><a href="#the-optimal-weighting-matrix" id="toc-the-optimal-weighting-matrix" class="nav-link" data-scroll-target="#the-optimal-weighting-matrix"><span class="header-section-number">13.5.3</span> The Optimal Weighting Matrix</a></li>
  </ul></li>
  <li><a href="#the-generalized-method-of-moments" id="toc-the-generalized-method-of-moments" class="nav-link" data-scroll-target="#the-generalized-method-of-moments"><span class="header-section-number">13.6</span> The Generalized Method of Moments</a>
  <ul class="collapse">
  <li><a href="#the-optimal-weighting-matrix-1" id="toc-the-optimal-weighting-matrix-1" class="nav-link" data-scroll-target="#the-optimal-weighting-matrix-1"><span class="header-section-number">13.6.1</span> The Optimal Weighting Matrix</a></li>
  <li><a href="#feasible-efficient-gmm" id="toc-feasible-efficient-gmm" class="nav-link" data-scroll-target="#feasible-efficient-gmm"><span class="header-section-number">13.6.2</span> Feasible Efficient GMM</a></li>
  </ul></li>
  <li><a href="#two-step-estimators" id="toc-two-step-estimators" class="nav-link" data-scroll-target="#two-step-estimators"><span class="header-section-number">13.7</span> Two-Step Estimators</a>
  <ul class="collapse">
  <li><a href="#setup-1" id="toc-setup-1" class="nav-link" data-scroll-target="#setup-1"><span class="header-section-number">13.7.1</span> Setup</a></li>
  <li><a href="#asymptotic-distribution-1" id="toc-asymptotic-distribution-1" class="nav-link" data-scroll-target="#asymptotic-distribution-1"><span class="header-section-number">13.7.2</span> Asymptotic Distribution</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">13.8</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../lectures/extremum-estimators.html">Extremum Estimators</a></li><li class="breadcrumb-item"><a href="../lectures/extremum_theory.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In the previous chapter, we introduced three classes of extremum estimators — maximum likelihood, GMM, and minimum distance — with examples from each of our prototype models. Now we turn to the statistical theory that governs these estimators. Recall the two key properties we set out to establish:</p>
<ol type="1">
<li><strong>Consistency</strong>: Does <span class="math inline">\(\hat{\theta}\rightarrow\theta_{0}\)</span> as the sample grows?</li>
<li><strong>Inference</strong>: What is the sampling distribution of <span class="math inline">\(\hat{\theta}\)</span> around <span class="math inline">\(\theta_{0}\)</span>?</li>
</ol>
<p>The results in this chapter apply broadly to all extremum estimators, and then we specialize to maximum likelihood, minimum distance, and GMM in turn. Throughout, we use our prototype models to illustrate how the theory translates into practice.</p>
<section id="definitions" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="definitions"><span class="header-section-number">13.1</span> Definitions</h2>
<p>We begin by formally defining the classes of estimators we will study. The broadest class is the <strong>extremum estimator</strong>.</p>
<div id="def-extremum" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.1 (Extremum Estimator)</strong></span> <span class="math inline">\(\hat{\theta}\)</span> is an <strong>extremum estimator</strong> if: <span class="math display">\[\hat{\theta} = \arg\max_{\theta\in\Theta}Q_{N}(\theta)\]</span> where <span class="math inline">\(\Theta\subset\mathbb{R}^{p}\)</span> and <span class="math inline">\(Q_{N}(\cdot)\)</span> is some objective function that depends on the data.</p>
</div>
<p>This is a very broad definition. All of the estimators we encountered in the previous chapter fall into this class. What distinguishes them is the structure of <span class="math inline">\(Q_{N}\)</span>.</p>
<section id="m-estimators" class="level3" data-number="13.1.1">
<h3 data-number="13.1.1" class="anchored" data-anchor-id="m-estimators"><span class="header-section-number">13.1.1</span> M-estimators</h3>
<p>An important subclass of extremum estimators arises when the objective function is an average over the sample:</p>
<div id="def-m-estimator" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.2 (M-estimator)</strong></span> <span class="math inline">\(\hat{\theta}\)</span> is an <strong>M-estimator</strong> if: <span class="math display">\[Q_{N}(\theta) = \frac{1}{N}\sum_{n=1}^{N}m(\mathbf{w}_{n},\theta)\]</span> for some known function <span class="math inline">\(m\)</span>.</p>
</div>
<p>The “M” stands for “maximum” (or “minimum”). Two of our workhorse estimators are M-estimators:</p>
<ul>
<li><strong>Maximum Likelihood</strong>: <span class="math inline">\(m(\mathbf{w}_{n},\theta) = \log f(y_{n}|\mathbf{x}_{n},\theta)\)</span>. This is the log-likelihood contribution of observation <span class="math inline">\(n\)</span>.</li>
<li><strong>Nonlinear Least Squares</strong>: <span class="math inline">\(m(\mathbf{w}_{n},\theta) = -(y_{n}-\varphi(\mathbf{x}_{n},\theta))^{2}\)</span>. Here <span class="math inline">\(\varphi(\mathbf{x},\theta)\)</span> is a regression function and the objective penalizes deviations of <span class="math inline">\(y\)</span> from its conditional mean.</li>
</ul>
</section>
<section id="gmm-estimator" class="level3" data-number="13.1.2">
<h3 data-number="13.1.2" class="anchored" data-anchor-id="gmm-estimator"><span class="header-section-number">13.1.2</span> GMM Estimator</h3>
<p>The GMM estimator is defined by a set of moment conditions <span class="math inline">\(\mathbb{E}[g(\mathbf{w},\theta_{0})]=\mathbf{0}\)</span>:</p>
<div id="def-gmm" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.3 (GMM Estimator)</strong></span> <span class="math display">\[Q_{N}(\theta) = -\frac{1}{2}\mathbf{g}_{N}(\theta)'\hat{\mathbf{W}}\mathbf{g}_{N}(\theta),\qquad\mathbf{g}_{N}(\theta)=\frac{1}{N}\sum_{n}g(\mathbf{w}_{n},\theta)\]</span> where <span class="math inline">\(\hat{\mathbf{W}}\)</span> is a positive definite weighting matrix.</p>
</div>
<p>Note that GMM is itself an M-estimator with <span class="math inline">\(m(\mathbf{w}_{n},\theta)=-\frac{1}{2}g(\mathbf{w}_{n},\theta)'\hat{\mathbf{W}}g(\mathbf{w}_{n},\theta)\)</span> (after expanding the quadratic form). We will return to the specific properties of GMM in a <a href="#the-generalized-method-of-moments">later section</a>.</p>
</section>
<section id="minimum-distance-estimator" class="level3" data-number="13.1.3">
<h3 data-number="13.1.3" class="anchored" data-anchor-id="minimum-distance-estimator"><span class="header-section-number">13.1.3</span> Minimum Distance Estimator</h3>
<p>The minimum distance estimator works with a first-stage reduced-form estimate <span class="math inline">\(\hat{\pi}\)</span> and model restrictions <span class="math inline">\(\psi(\pi,\theta)\)</span>:</p>
<div id="def-md" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.4 (Minimum Distance Estimator)</strong></span> <span class="math display">\[Q_{N}(\theta) = -\frac{1}{2}\psi(\hat{\pi}_{N},\theta)'\hat{\mathbf{W}}\psi(\hat{\pi}_{N},\theta)\]</span> where <span class="math inline">\(\psi(\pi_{0},\theta_{0})=\mathbf{0}\)</span> and <span class="math inline">\(\sqrt{N}(\hat{\pi}_{N}-\pi_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\Omega)\)</span>.</p>
</div>
<p>The minimum distance estimator differs from GMM in that the objective depends on the data only through the first-stage statistic <span class="math inline">\(\hat{\pi}\)</span>, rather than through the individual observations directly. We will study its asymptotic properties in a <a href="#minimum-distance-estimators">dedicated section</a>.</p>
</section>
</section>
<section id="consistency" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="consistency"><span class="header-section-number">13.2</span> Consistency</h2>
<p>An extremum estimator solves <span class="math inline">\(\hat{\theta} = \arg\max_{\theta\in\Theta}Q_{N}(\theta)\)</span>. Let <span class="math inline">\(Q_{0}(\theta)\)</span> denote the <em>population</em> analogue: the probability limit of <span class="math inline">\(Q_{N}(\theta)\)</span>.</p>
<p>When can we guarantee that <span class="math inline">\(\hat{\theta}\rightarrow_{p}\theta_{0}\)</span>? Intuitively, two conditions are needed:</p>
<ol type="1">
<li><strong>Identification</strong>: The population objective <span class="math inline">\(Q_{0}(\theta)\)</span> must be <em>uniquely</em> maximized at <span class="math inline">\(\theta_{0}\)</span>. If there were multiple maximizers, convergence of <span class="math inline">\(Q_{N}\)</span> to <span class="math inline">\(Q_{0}\)</span> would not pin down which one <span class="math inline">\(\hat{\theta}\)</span> approaches.</li>
<li><strong>Convergence</strong>: <span class="math inline">\(Q_{N}(\theta)\)</span> must converge to <span class="math inline">\(Q_{0}(\theta)\)</span> in a sufficiently strong sense that the maximizer of <span class="math inline">\(Q_{N}\)</span> tracks the maximizer of <span class="math inline">\(Q_{0}\)</span>.</li>
</ol>
<p>These two conditions are the backbone of every consistency argument. The precise form of the convergence condition depends on the structure of the problem.</p>
<div id="thm-consistency-compact" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.1 (Consistency with Compactness)</strong></span> Suppose the following conditions hold:</p>
<ol type="1">
<li><span class="math inline">\(\Theta\)</span> is a compact subset of <span class="math inline">\(\mathbb{R}^{p}\)</span></li>
<li><span class="math inline">\(Q_{N}(\theta)\)</span> is continuous in <span class="math inline">\(\theta\)</span> for all realizations of the data</li>
<li><span class="math inline">\(Q_{N}(\theta)\)</span> is a measurable function of the data for all <span class="math inline">\(\theta\in\Theta\)</span></li>
</ol>
<p>and additionally:</p>
<ol type="a">
<li><strong>Identification</strong>: <span class="math inline">\(Q_{0}(\theta)\)</span> is uniquely maximized at <span class="math inline">\(\theta_{0}\in\Theta\)</span></li>
<li><strong>Uniform Convergence</strong>: <span class="math inline">\(\sup_{\theta\in\Theta}|Q_{N}(\theta)-Q_{0}(\theta)|\rightarrow_{p}0\)</span></li>
</ol>
<p>Then <span class="math inline">\(\hat{\theta}\rightarrow_{p}\theta_{0}\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof Sketch
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The idea is straightforward. Pick any open neighborhood <span class="math inline">\(\mathcal{N}\)</span> around <span class="math inline">\(\theta_{0}\)</span>. We want to show that <span class="math inline">\(\hat{\theta}\in\mathcal{N}\)</span> with probability approaching 1.</p>
<p>Since <span class="math inline">\(\theta_{0}\)</span> uniquely maximizes <span class="math inline">\(Q_{0}\)</span> and <span class="math inline">\(\Theta\setminus\mathcal{N}\)</span> is compact (closed subset of a compact set), there exists a gap: <span class="math display">\[\varepsilon = Q_{0}(\theta_{0}) - \sup_{\theta\in\Theta\setminus\mathcal{N}}Q_{0}(\theta) &gt; 0\]</span></p>
<p>Now, by uniform convergence: <span class="math display">\[Q_{N}(\hat{\theta}) \geq Q_{N}(\theta_{0}) \geq Q_{0}(\theta_{0}) - \varepsilon/2\]</span> with probability approaching 1. At the same time, for any <span class="math inline">\(\theta\in\Theta\setminus\mathcal{N}\)</span>: <span class="math display">\[Q_{N}(\theta) \leq Q_{0}(\theta) + \varepsilon/2 \leq Q_{0}(\theta_{0}) - \varepsilon/2\]</span> also with probability approaching 1. Thus <span class="math inline">\(\hat{\theta}\)</span> cannot lie outside <span class="math inline">\(\mathcal{N}\)</span>, and since <span class="math inline">\(\mathcal{N}\)</span> was arbitrary, <span class="math inline">\(\hat{\theta}\rightarrow_{p}\theta_{0}\)</span>.</p>
</div>
</div>
</div>
<p>Compactness is a strong assumption. Many parameter spaces of interest are not bounded (e.g.&nbsp;regression coefficients). The following result relaxes compactness at the cost of requiring concavity.</p>
<div id="thm-consistency-concave" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.2 (Consistency without Compactness)</strong></span> Suppose the following conditions hold:</p>
<ol type="1">
<li><span class="math inline">\(\theta_{0}\in\text{int}(\Theta)\)</span></li>
<li><span class="math inline">\(Q_{N}(\theta)\)</span> is concave in <span class="math inline">\(\theta\)</span> for all realizations of the data</li>
<li><span class="math inline">\(Q_{N}(\theta)\)</span> is a measurable function of the data for all <span class="math inline">\(\theta\in\Theta\)</span></li>
</ol>
<p>and additionally:</p>
<ol type="a">
<li><strong>Identification</strong>: <span class="math inline">\(Q_{0}(\theta)\)</span> is uniquely maximized at <span class="math inline">\(\theta_{0}\in\Theta\)</span></li>
<li><strong>Pointwise Convergence</strong>: <span class="math inline">\(Q_{N}(\theta)\rightarrow_{p}Q_{0}(\theta)\)</span> for all <span class="math inline">\(\theta\in\Theta\)</span></li>
</ol>
<p>Then <span class="math inline">\(\hat{\theta}\rightarrow_{p}\theta_{0}\)</span>.</p>
</div>
<p>The key insight is that concavity turns <em>pointwise</em> convergence into <em>uniform</em> convergence on compact subsets (this follows from a result in convex analysis due to Rockafellar, 1970). Combined with the fact that <span class="math inline">\(\theta_{0}\)</span> is an interior point, one can construct a compact set around <span class="math inline">\(\theta_{0}\)</span> that traps <span class="math inline">\(\hat{\theta}\)</span> with probability approaching 1 and then apply the logic of <a href="#thm-consistency-compact" class="quarto-xref">Theorem&nbsp;<span>13.1</span></a>.</p>
<section id="uniform-convergence" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="uniform-convergence"><span class="header-section-number">13.2.1</span> Uniform Convergence</h3>
<p>Condition (b) of <a href="#thm-consistency-compact" class="quarto-xref">Theorem&nbsp;<span>13.1</span></a> requires <em>uniform</em> convergence of <span class="math inline">\(Q_{N}\)</span> to <span class="math inline">\(Q_{0}\)</span>. This is stronger than pointwise convergence and deserves some attention. For M-estimators of the form <span class="math inline">\(Q_{N}(\theta)=\frac{1}{N}\sum_{n=1}^{N}m(\mathbf{w}_{n},\theta)\)</span>, the question reduces to asking for a <em>uniform law of large numbers</em>. The following result provides simple sufficient conditions.</p>
<div id="thm-ulln" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.3 (Uniform Law of Large Numbers)</strong></span> Suppose that <span class="math inline">\(\{\mathbf{w}_{n}\}_{n=1}^{N}\)</span> is an ergodic stationary sequence and:</p>
<ol type="1">
<li><span class="math inline">\(\Theta\)</span> is compact</li>
<li><span class="math inline">\(m(\mathbf{w},\theta)\)</span> is continuous in <span class="math inline">\(\theta\)</span> for all <span class="math inline">\(\mathbf{w}\)</span></li>
<li><span class="math inline">\(m(\mathbf{w},\theta)\)</span> is measurable in <span class="math inline">\(\mathbf{w}\)</span> for all <span class="math inline">\(\theta\)</span></li>
<li>There exists <span class="math inline">\(d(\mathbf{w})\)</span> with <span class="math inline">\(|m(\mathbf{w},\theta)|\leq d(\mathbf{w})\)</span> for all <span class="math inline">\(\theta\in\Theta\)</span> and <span class="math inline">\(\mathbb{E}[d(\mathbf{w})]&lt;\infty\)</span></li>
</ol>
<p>Then:</p>
<ol type="a">
<li><span class="math inline">\(\sup_{\theta\in\Theta}|Q_{N}(\theta)-Q_{0}(\theta)|\rightarrow_{p}0\)</span>; and</li>
<li><span class="math inline">\(Q_{0}(\theta) = \mathbb{E}[m(\mathbf{w},\theta)]\)</span> is continuous in <span class="math inline">\(\theta\)</span>.</li>
</ol>
</div>
<p>In practice, the dominance condition (4) is verified by checking <span class="math inline">\(\mathbb{E}[\sup_{\theta\in\Theta}|m(\mathbf{w},\theta)|]&lt;\infty\)</span>. This is straightforward for many common estimators. See <span class="citation" data-cites="newey1994large">Newey and McFadden (<a href="../references.html#ref-newey1994large" role="doc-biblioref">1994</a>)</span> for a comprehensive treatment of these results.</p>
</section>
<section id="consistency-of-maximum-likelihood" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="consistency-of-maximum-likelihood"><span class="header-section-number">13.2.2</span> Consistency of Maximum Likelihood</h3>
<p>For maximum likelihood, the objective is <span class="math inline">\(Q_{N}(\theta)=\frac{1}{N}\sum_{n}^{N}\log f(\mathbf{w}_{n};\theta)\)</span>, and the population analogue is <span class="math inline">\(Q_{0}(\theta) = \mathbb{E}_{\theta_{0}}[\log f(\mathbf{w};\theta)]\)</span>. Identification for MLE has an elegant justification through the <strong>Kullback-Leibler inequality</strong>: for any two densities <span class="math inline">\(g\)</span> and <span class="math inline">\(h\)</span>,</p>
<p><span class="math display">\[\mathbb{E}_{g}\left[\log\frac{g(\mathbf{w})}{h(\mathbf{w})}\right]\geq 0\]</span></p>
<p>with equality if and only if <span class="math inline">\(g=h\)</span> almost everywhere. Applying this with <span class="math inline">\(g(\cdot) = f(\cdot;\theta_{0})\)</span> and <span class="math inline">\(h(\cdot) = f(\cdot;\theta)\)</span> gives:</p>
<p><span class="math display">\[\mathbb{E}_{\theta_{0}}[\log f(\mathbf{w};\theta_{0})] \geq \mathbb{E}_{\theta_{0}}[\log f(\mathbf{w};\theta)]\]</span></p>
<p>with equality if and only if <span class="math inline">\(f(\cdot;\theta)=f(\cdot;\theta_{0})\)</span> almost everywhere. Thus, as long as different values of <span class="math inline">\(\theta\)</span> imply different densities (a natural notion of identification for parametric models), the population log-likelihood is uniquely maximized at <span class="math inline">\(\theta_{0}\)</span>.</p>
<div id="thm-consistency-mle" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.4 (Consistency of Maximum Likelihood)</strong></span> Suppose that <span class="math inline">\(\{\mathbf{w}_{n}\}\)</span> is ergodic stationary with density <span class="math inline">\(f(\mathbf{w};\theta_{0})\)</span> and that <span class="math inline">\(\theta_{0}\in\Theta\)</span>. If:</p>
<ol type="1">
<li><span class="math inline">\(\Theta\)</span> is compact</li>
<li><span class="math inline">\(\log f(\mathbf{w};\theta)\)</span> is continuous in <span class="math inline">\(\theta\)</span></li>
<li><span class="math inline">\(f(\mathbf{w};\theta_{0})\neq f(\mathbf{w};\theta)\)</span> with positive probability for all <span class="math inline">\(\theta\neq\theta_{0}\)</span> (<strong>identification</strong>)</li>
<li><span class="math inline">\(\mathbb{E}[\sup_{\theta\in\Theta}|\log f(\mathbf{w};\theta)|]&lt;\infty\)</span> (<strong>dominance</strong>)</li>
</ol>
<p>Then <span class="math inline">\(\hat{\theta}_{ML}\rightarrow_{p}\theta_{0}\)</span>.</p>
</div>
<p>Notice that identification here takes a model-specific form: we need different parameter values to imply different distributions for the data. This is a consequence of the fact that MLE relies on a fully specified parametric model.</p>
<p>An analogous result holds without compactness when the log-likelihood is concave in <span class="math inline">\(\theta\)</span> (as is often the case for exponential family models), replacing (1) with <span class="math inline">\(\theta_{0}\in\text{int}(\Theta)\)</span> and (4) with pointwise moment conditions.</p>
</section>
</section>
<section id="asymptotic-normality" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="asymptotic-normality"><span class="header-section-number">13.3</span> Asymptotic Normality</h2>
<p>Having established when <span class="math inline">\(\hat{\theta}\rightarrow_{p}\theta_{0}\)</span>, we now turn to characterizing the <em>rate</em> and <em>distribution</em> of <span class="math inline">\(\hat{\theta}\)</span> around <span class="math inline">\(\theta_{0}\)</span>. The answer will justify the standard errors and confidence intervals that we routinely compute in applied work.</p>
<p>Consider an M-estimator: <span class="math inline">\(Q_{N}(\theta) = \frac{1}{N}\sum_{n=1}^{N}m(\mathbf{w}_{n},\theta)\)</span>. Define the <strong>score</strong> (gradient) and <strong>Hessian</strong> of <span class="math inline">\(m\)</span>:</p>
<p><span class="math display">\[\mathbf{s}(\mathbf{w},\theta) = \frac{\partial m(\mathbf{w},\theta)}{\partial\theta}\qquad(p\times 1)\]</span></p>
<p><span class="math display">\[\mathbf{H}(\mathbf{w},\theta) = \frac{\partial^{2}m(\mathbf{w},\theta)}{\partial\theta\partial\theta'}\qquad(p\times p)\]</span></p>
<section id="derivation-via-the-mean-value-theorem" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="derivation-via-the-mean-value-theorem"><span class="header-section-number">13.3.1</span> Derivation via the Mean Value Theorem</h3>
<p>Since <span class="math inline">\(\hat{\theta}\)</span> maximizes <span class="math inline">\(Q_{N}\)</span>, the first-order condition gives: <span class="math display">\[\frac{1}{N}\sum_{n=1}^{N}\mathbf{s}(\mathbf{w}_{n},\hat{\theta}) = \mathbf{0}\]</span></p>
<p>A mean value expansion around <span class="math inline">\(\theta_{0}\)</span> yields: <span class="math display">\[\mathbf{0} = \frac{1}{N}\sum_{n}\mathbf{s}(\mathbf{w}_{n},\theta_{0}) + \left[\frac{1}{N}\sum_{n}\mathbf{H}(\mathbf{w}_{n},\bar{\theta})\right](\hat{\theta}-\theta_{0})\]</span></p>
<p>where <span class="math inline">\(\bar{\theta}\)</span> lies between <span class="math inline">\(\hat{\theta}\)</span> and <span class="math inline">\(\theta_{0}\)</span> (applied row-by-row). Rearranging: <span class="math display">\[\sqrt{N}(\hat{\theta}-\theta_{0}) = -\left[\frac{1}{N}\sum_{n}\mathbf{H}(\mathbf{w}_{n},\bar{\theta})\right]^{-1}\frac{1}{\sqrt{N}}\sum_{n}\mathbf{s}(\mathbf{w}_{n},\theta_{0})\]</span></p>
<p>Now apply two standard arguments:</p>
<ol type="1">
<li>By the <strong>Central Limit Theorem</strong>: <span class="math inline">\(\frac{1}{\sqrt{N}}\sum_{n}\mathbf{s}(\mathbf{w}_{n},\theta_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\Sigma)\)</span> where <span class="math inline">\(\Sigma = \mathbb{E}[\mathbf{s}(\mathbf{w},\theta_{0})\mathbf{s}(\mathbf{w},\theta_{0})']\)</span>.</li>
<li>By a <strong>Law of Large Numbers</strong> and continuity: <span class="math inline">\(\frac{1}{N}\sum_{n}\mathbf{H}(\mathbf{w}_{n},\bar{\theta})\rightarrow_{p}\mathbb{E}[\mathbf{H}(\mathbf{w},\theta_{0})]\)</span>, using that <span class="math inline">\(\bar{\theta}\rightarrow_{p}\theta_{0}\)</span>.</li>
</ol>
<p>Combining these via Slutsky’s theorem gives the result.</p>
<div id="thm-asymptotic-normality" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.5 (Asymptotic Normality for M-estimators)</strong></span> Suppose that the consistency conditions hold and additionally:</p>
<ol type="1">
<li><span class="math inline">\(\theta_{0}\in\text{int}(\Theta)\)</span></li>
<li><span class="math inline">\(m(\mathbf{w},\theta)\)</span> is twice continuously differentiable in <span class="math inline">\(\theta\)</span></li>
<li><span class="math inline">\(\frac{1}{\sqrt{N}}\sum_{n}\mathbf{s}(\mathbf{w}_{n},\theta_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\Sigma)\)</span> with <span class="math inline">\(\Sigma\)</span> positive definite</li>
<li><span class="math inline">\(\mathbb{E}[\sup_{\theta\in\mathcal{N}(\theta_{0})}\|\mathbf{H}(\mathbf{w},\theta)\|]&lt;\infty\)</span> for some neighborhood <span class="math inline">\(\mathcal{N}(\theta_{0})\)</span></li>
<li><span class="math inline">\(\mathbb{E}[\mathbf{H}(\mathbf{w},\theta_{0})]\)</span> is nonsingular</li>
</ol>
<p>Then: <span class="math display">\[\sqrt{N}(\hat{\theta}-\theta_{0})\rightarrow_{d}\mathcal{N}\left(\mathbf{0},\ \mathbb{E}[\mathbf{H}]^{-1}\Sigma\mathbb{E}[\mathbf{H}]^{-1}\right)\]</span></p>
<p>where <span class="math inline">\(\mathbb{E}[\mathbf{H}]=\mathbb{E}[\mathbf{H}(\mathbf{w},\theta_{0})]\)</span> and <span class="math inline">\(\Sigma = \mathbb{E}[\mathbf{s}(\mathbf{w},\theta_{0})\mathbf{s}(\mathbf{w},\theta_{0})']\)</span>.</p>
</div>
<p>The asymptotic variance <span class="math inline">\(\mathbb{E}[\mathbf{H}]^{-1}\Sigma\mathbb{E}[\mathbf{H}]^{-1}\)</span> is often called the <strong>sandwich formula</strong>. In practice, we replace the population expectations with sample analogues: <span class="math display">\[\widehat{\mathbb{V}}[\hat{\theta}] = \hat{H}^{-1}\hat{\Sigma}\hat{H}^{-1}/N\]</span> where <span class="math inline">\(\hat{H} = \frac{1}{N}\sum_{n}\mathbf{H}(\mathbf{w}_{n},\hat{\theta})\)</span> and <span class="math inline">\(\hat{\Sigma} = \frac{1}{N}\sum_{n}\mathbf{s}(\mathbf{w}_{n},\hat{\theta})\mathbf{s}(\mathbf{w}_{n},\hat{\theta})'\)</span>.</p>
</section>
<section id="the-information-matrix-equality" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="the-information-matrix-equality"><span class="header-section-number">13.3.2</span> The Information Matrix Equality</h3>
<p>For maximum likelihood, <span class="math inline">\(m(\mathbf{w},\theta)=\log f(\mathbf{w};\theta)\)</span>, and a remarkable simplification occurs. Under standard regularity conditions, the <strong>information matrix equality</strong> holds:</p>
<p><span class="math display">\[\mathcal{I}(\theta_{0}) \equiv \mathbb{E}\left[\mathbf{s}(\mathbf{w},\theta_{0})\mathbf{s}(\mathbf{w},\theta_{0})'\right] = -\mathbb{E}\left[\mathbf{H}(\mathbf{w},\theta_{0})\right]\]</span></p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why does this hold?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Since <span class="math inline">\(\int f(\mathbf{w};\theta)d\mathbf{w}=1\)</span> for all <span class="math inline">\(\theta\)</span>, differentiating under the integral sign with respect to <span class="math inline">\(\theta\)</span> gives: <span class="math display">\[\int\frac{\partial f(\mathbf{w};\theta)}{\partial\theta}d\mathbf{w} = 0\]</span> which is <span class="math inline">\(\mathbb{E}_{\theta}[\mathbf{s}(\mathbf{w},\theta)]=0\)</span>. Differentiating again: <span class="math display">\[\int\frac{\partial^{2}\log f}{\partial\theta\partial\theta'}f\ d\mathbf{w} + \int\frac{\partial\log f}{\partial\theta}\frac{\partial\log f}{\partial\theta'}f\ d\mathbf{w} = 0\]</span> which yields <span class="math inline">\(\mathbb{E}[\mathbf{H}]+\mathbb{E}[\mathbf{s}\mathbf{s}'] = 0\)</span>, i.e.&nbsp;<span class="math inline">\(\Sigma = -\mathbb{E}[\mathbf{H}]\)</span>.</p>
</div>
</div>
</div>
<p>This means that for MLE, the sandwich formula collapses to: <span class="math display">\[\sqrt{N}(\hat{\theta}_{ML}-\theta_{0})\rightarrow_{d}\mathcal{N}\left(\mathbf{0},\ \mathcal{I}(\theta_{0})^{-1}\right)\]</span></p>
<p>The matrix <span class="math inline">\(\mathcal{I}(\theta)\)</span> is called the <strong>Fisher information matrix</strong>. The MLE variance can be estimated using <em>either</em> the Hessian or the outer product of the score — or indeed the sandwich (which is robust to certain forms of misspecification).</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Probit Standard Errors
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="exm-probit_se" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.1</strong></span> Let’s illustrate the asymptotic variance formula for the probit model from the Generalized Roy Model (<a href="identification_roy.html#exm-roy_estimation" class="quarto-xref">Example&nbsp;<span>7.1</span></a>). The probit log-likelihood for a single observation is:</p>
<p><span class="math display">\[m(\mathbf{w}_{n},\gamma) = D_{n}\log\Phi(\mathbf{w}_{n}\gamma) + (1-D_{n})\log(1-\Phi(\mathbf{w}_{n}\gamma))\]</span></p>
<p>where <span class="math inline">\(\mathbf{w}_{n} = [1,X_{n},Z_{n}]\)</span>. Rather than deriving the Hessian and score analytically, we can use automatic differentiation — a tool covered in more detail in the <a href="../appendices/autodiff.html">appendix</a>.</p>
<div id="b6d856ca" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Distributions</span>, <span class="bu">Optim</span>, <span class="bu">Random</span>, <span class="bu">ForwardDiff</span>, <span class="bu">LinearAlgebra</span>, <span class="bu">Plots</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">sim_data</span>(γ,β<span class="fl">0</span>,β<span class="fl">1</span>,N ; ρ_0 <span class="op">=</span> <span class="fl">0.3</span>, ρ_1 <span class="op">=</span> <span class="op">-</span><span class="fl">0.3</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">Normal</span>(),N)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">Normal</span>(),N)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">Normal</span>(),N)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    U0 <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">Normal</span>(),N) <span class="op">.+</span> ρ_0<span class="op">.*</span>v</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    U1 <span class="op">=</span> <span class="fu">rand</span>(<span class="fu">Normal</span>(),N) <span class="op">.+</span> ρ_1<span class="op">.*</span>v</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> (γ[<span class="fl">1</span>] <span class="op">.+</span> γ[<span class="fl">2</span>]<span class="op">*</span>X <span class="op">.+</span> γ[<span class="fl">3</span>]<span class="op">*</span>Z <span class="op">.-</span> v) <span class="op">.&gt;</span> <span class="fl">0</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> β<span class="fl">0</span>[<span class="fl">1</span>] <span class="op">.+</span> β<span class="fl">0</span>[<span class="fl">2</span>]<span class="op">.*</span>X <span class="op">.+</span> U0</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    Y1 <span class="op">=</span> β<span class="fl">1</span>[<span class="fl">1</span>] <span class="op">.+</span> β<span class="fl">1</span>[<span class="fl">2</span>]<span class="op">.*</span>X <span class="op">.+</span> U1</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    Y[D<span class="op">.==</span><span class="fl">1</span>] <span class="op">.=</span> Y1[D<span class="op">.==</span><span class="fl">1</span>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (;X,Z,Y,D)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">log_likelihood</span>(γ,data)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    (;D,X,Z) <span class="op">=</span> data</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> <span class="fl">0</span>.</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    Fv <span class="op">=</span> <span class="fu">Normal</span>()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> <span class="fu">eachindex</span>(D)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        xg <span class="op">=</span> γ[<span class="fl">1</span>] <span class="op">+</span> γ[<span class="fl">2</span>]<span class="op">*</span>X[n] <span class="op">+</span> γ[<span class="fl">3</span>]<span class="op">*</span>Z[n]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> D[n] <span class="op">==</span> <span class="fl">1</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            ll <span class="op">+=</span> <span class="fu">log</span>(<span class="fu">cdf</span>(Fv,xg))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            ll <span class="op">+=</span> <span class="fu">log</span>(<span class="fl">1</span><span class="fu">-cdf</span>(Fv,xg))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">end</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ll <span class="op">/</span> <span class="fu">length</span>(D)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">estimate_probit</span>(data)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> <span class="fu">optimize</span>(<span class="fu">x-&gt;-log_likelihood</span>(x,data),<span class="fu">zeros</span>(<span class="fl">3</span>),<span class="fu">Newton</span>(),autodiff<span class="op">=:</span>forward)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res.minimizer</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>estimate_probit (generic function with 1 method)</code></pre>
</div>
</div>
<p>Now let’s estimate the probit model on a single dataset and compute standard errors using the information matrix. We use <code>ForwardDiff</code> to compute the score and Hessian numerically.</p>
<div id="252b4e9c" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.3</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>beta1 <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.5</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">Random</span>.<span class="fu">seed!</span>(<span class="fl">123</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="fu">sim_data</span>(gamma, beta0, beta1, <span class="fl">5000</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>γ_hat <span class="op">=</span> <span class="fu">estimate_probit</span>(data)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute score for each observation</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">score_n</span>(n, γ, data)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">ll_n</span>(g)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        xg <span class="op">=</span> g[<span class="fl">1</span>] <span class="op">+</span> g[<span class="fl">2</span>]<span class="op">*</span>data.X[n] <span class="op">+</span> g[<span class="fl">3</span>]<span class="op">*</span>data.Z[n]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> data.D[n] <span class="op">==</span> <span class="fl">1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fu">log</span>(<span class="fu">cdf</span>(<span class="fu">Normal</span>(),xg))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="fu">log</span>(<span class="fl">1</span><span class="fu">-cdf</span>(<span class="fu">Normal</span>(),xg))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">end</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ForwardDiff.<span class="fu">gradient</span>(ll_n, γ)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="fu">length</span>(data.D)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Outer product of scores (estimate of Fisher information)</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>Σ_hat <span class="op">=</span> <span class="fu">zeros</span>(<span class="fl">3</span>,<span class="fl">3</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>N</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="fu">score_n</span>(n, γ_hat, data)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    Σ_hat <span class="op">+=</span> s <span class="op">*</span> s<span class="op">'</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>Σ_hat <span class="op">./=</span> N</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Hessian of average log-likelihood</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>H_hat <span class="op">=</span> ForwardDiff.<span class="fu">hessian</span>(g <span class="op">-&gt;</span> <span class="fu">log_likelihood</span>(g, data), γ_hat)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Asymptotic variance (three ways)</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>V_sandwich <span class="op">=</span> <span class="fu">inv</span>(H_hat) <span class="op">*</span> Σ_hat <span class="op">*</span> <span class="fu">inv</span>(H_hat) <span class="op">/</span> N</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>V_hessian <span class="op">=</span> <span class="fu">-inv</span>(H_hat) <span class="op">/</span> N</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>V_opg <span class="op">=</span> <span class="fu">inv</span>(Σ_hat) <span class="op">/</span> N</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>se_sandwich <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_sandwich))</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>se_hessian <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_hessian))</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>se_opg <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_opg))</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Estimates: </span><span class="sc">$</span>(<span class="fu">round</span>.(γ_hat,digits<span class="op">=</span><span class="fl">3</span>))<span class="st">"</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"SE (sandwich): </span><span class="sc">$</span>(<span class="fu">round</span>.(se_sandwich,digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"SE (Hessian):  </span><span class="sc">$</span>(<span class="fu">round</span>.(se_hessian,digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"SE (OPG):      </span><span class="sc">$</span>(<span class="fu">round</span>.(se_opg,digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimates: [-0.007, 0.473, 0.475]
SE (sandwich): [0.019, 0.0212, 0.0209]
SE (Hessian):  [0.019, 0.0209, 0.0207]
SE (OPG):      [0.0191, 0.0205, 0.0206]</code></pre>
</div>
</div>
<p>Let’s verify these asymptotic standard errors against a Monte Carlo simulation. If the asymptotic theory is working, the standard deviation of the Monte Carlo estimates should be close to the asymptotic SE.</p>
<div id="e28d5017" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>gamma_mc <span class="op">=</span> <span class="fu">mapreduce</span>(vcat, <span class="fl">1</span><span class="op">:</span><span class="fl">500</span>) <span class="cf">do</span> b</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="fu">sim_data</span>(gamma, beta0, beta1, <span class="fl">5000</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">estimate_probit</span>(d)<span class="ch">'</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>se_mc <span class="op">=</span> <span class="fu">std</span>.(<span class="fu">eachcol</span>(gamma_mc))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"SE (Monte Carlo): </span><span class="sc">$</span>(<span class="fu">round</span>.(se_mc,digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"SE (asymptotic):  </span><span class="sc">$</span>(<span class="fu">round</span>.(se_hessian,digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>SE (Monte Carlo): [0.0209, 0.0204, 0.0207]
SE (asymptotic):  [0.019, 0.0209, 0.0207]</code></pre>
</div>
</div>
<p>We can also plot the Monte Carlo distribution against the asymptotic normal approximation.</p>
<div id="286adc6d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>pl <span class="op">=</span> [begin</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">histogram</span>(gamma_mc[<span class="op">:</span>,j], normalize<span class="op">=:</span>pdf, label<span class="op">=</span><span class="cn">false</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    xgrid <span class="op">=</span> <span class="fu">range</span>(<span class="fu">extrema</span>(gamma_mc[<span class="op">:</span>,j])<span class="op">...</span>, length<span class="op">=</span><span class="fl">100</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot!</span>(xgrid, <span class="fu">pdf</span>.(<span class="fu">Normal</span>(gamma[j], se_hessian[j]), xgrid),</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="fl">2</span>, label<span class="op">=</span><span class="st">"Asymptotic Normal"</span>, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot!</span>(title <span class="op">=</span> <span class="st">"γ_</span><span class="sc">$</span>(j)<span class="st">"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span> for j <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pl<span class="op">...</span>, layout<span class="op">=</span>(<span class="fl">1</span>,<span class="fl">3</span>), size<span class="op">=</span>(<span class="fl">900</span>,<span class="fl">300</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<img src="data:image/png;base64,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">
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="the-delta-method" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="the-delta-method"><span class="header-section-number">13.3.3</span> The Delta Method</h3>
<p>In many settings, the parameters of direct interest are not <span class="math inline">\(\theta\)</span> itself but some smooth function <span class="math inline">\(g(\theta)\)</span>. For instance, in <a href="extremum_intro_examples.html#exm-search_likelihood" class="quarto-xref">Example&nbsp;<span>12.1</span></a> the search model is parameterized by <span class="math inline">\(\theta=(h,\delta,\mu,\sigma,w^{*})\)</span> but the economically meaningful objects include <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(b\)</span>, which are nonlinear functions of <span class="math inline">\(\theta\)</span>. The <strong>delta method</strong> provides the asymptotic distribution of such transformed parameters.</p>
<div id="thm-delta-method" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.6 (Delta Method)</strong></span> If <span class="math inline">\(\sqrt{N}(\hat{\theta}-\theta_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},V)\)</span> and <span class="math inline">\(g:\mathbb{R}^{p}\rightarrow\mathbb{R}^{k}\)</span> is continuously differentiable at <span class="math inline">\(\theta_{0}\)</span> with Jacobian <span class="math inline">\(\nabla g(\theta_{0})\)</span> of full row rank, then:</p>
<p><span class="math display">\[\sqrt{N}(g(\hat{\theta})-g(\theta_{0}))\rightarrow_{d}\mathcal{N}\left(\mathbf{0},\ \nabla g(\theta_{0})\ V\ \nabla g(\theta_{0})'\right)\]</span></p>
</div>
<p>The proof is a direct application of the continuous mapping theorem to the first-order Taylor expansion <span class="math inline">\(g(\hat{\theta})\approx g(\theta_{0})+\nabla g(\theta_{0})(\hat{\theta}-\theta_{0})\)</span>.</p>
<p>In practice, the Jacobian <span class="math inline">\(\nabla g\)</span> can be computed analytically or by automatic differentiation. This is convenient when <span class="math inline">\(g\)</span> is a complex function — for instance, when it involves solving the model as in the case of the reservation wage <span class="math inline">\(w^{*}\)</span> in the search model.</p>
</section>
</section>
<section id="efficiency" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="efficiency"><span class="header-section-number">13.4</span> Efficiency</h2>
<p>Given two consistent, asymptotically normal estimators <span class="math inline">\(\hat{\theta}_{1}\)</span> and <span class="math inline">\(\hat{\theta}_{2}\)</span>, we say <span class="math inline">\(\hat{\theta}_{1}\)</span> is <strong>asymptotically efficient</strong> relative to <span class="math inline">\(\hat{\theta}_{2}\)</span> if <span class="math inline">\(V_{2}-V_{1}\)</span> is positive semi-definite, where <span class="math inline">\(V_{j}\)</span> is the asymptotic variance of <span class="math inline">\(\hat{\theta}_{j}\)</span>. A natural question is: among the class of estimators we have discussed, is there a “best” one?</p>
<section id="efficiency-of-maximum-likelihood" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="efficiency-of-maximum-likelihood"><span class="header-section-number">13.4.1</span> Efficiency of Maximum Likelihood</h3>
<p>The answer is yes, under the assumption that the model is correctly specified. The MLE achieves the <strong>Cramér-Rao lower bound</strong>: for any consistent, asymptotically normal estimator <span class="math inline">\(\hat{\theta}\)</span> based on the likelihood,</p>
<p><span class="math display">\[V[\hat{\theta}] - \mathcal{I}(\theta_{0})^{-1}\geq 0\]</span></p>
<p>in the positive semi-definite sense. Since the MLE has asymptotic variance <span class="math inline">\(\mathcal{I}(\theta_{0})^{-1}\)</span>, no other estimator in this class can do better.</p>
<p>More concretely, one can show that MLE is efficient relative to <em>any</em> GMM estimator that uses moment conditions implied by the model. The argument proceeds by showing that for any GMM estimator with moments <span class="math inline">\(g(\mathbf{w},\theta)\)</span>, the difference in asymptotic variances is:</p>
<p><span class="math display">\[V_{GMM} - V_{MLE} = \mathbb{E}[\mathbf{m}\mathbf{s}']^{-1}\mathbb{E}[\mathbf{U}\mathbf{U}']\mathbb{E}[\mathbf{s}\mathbf{m}']^{-1}\geq 0\]</span></p>
<p>where <span class="math inline">\(\mathbf{m}\)</span> is the influence function of the GMM estimator and <span class="math inline">\(\mathbf{U} = \mathbf{m}-\mathbb{E}[\mathbf{m}\mathbf{s}']\mathbb{E}[\mathbf{s}\mathbf{s}']^{-1}\mathbf{s}\)</span> is the projection residual of <span class="math inline">\(\mathbf{m}\)</span> on <span class="math inline">\(\mathbf{s}\)</span>. This is non-negative by construction, and equals zero only when <span class="math inline">\(\mathbf{m}\)</span> is a linear function of <span class="math inline">\(\mathbf{s}\)</span> — i.e.&nbsp;when the GMM estimator fully exploits the likelihood.</p>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Discussion: Efficiency vs.&nbsp;Robustness
</div>
</div>
<div class="callout-body-container callout-body">
<p>The efficiency of MLE comes at a price: it requires the entire parametric model to be correctly specified. If the density <span class="math inline">\(f(\mathbf{w};\theta)\)</span> is wrong — even slightly — the MLE may still converge, but it will converge to a <em>pseudo-true</em> value that minimizes the Kullback-Leibler divergence to the truth, and the information matrix equality will fail. In contrast, GMM only requires the <em>moment conditions</em> to be correct, making it more robust to partial misspecification. The sandwich variance estimator <span class="math inline">\(\hat{H}^{-1}\hat{\Sigma}\hat{H}^{-1}\)</span> remains valid for MLE even under misspecification, which is why it is sometimes preferred in practice.</p>
</div>
</div>
</section>
</section>
<section id="minimum-distance-estimators" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="minimum-distance-estimators"><span class="header-section-number">13.5</span> Minimum Distance Estimators</h2>
<p>The minimum distance estimator takes a different approach from the M-estimators discussed above. Instead of directly optimizing an objective over the raw data, it works in two stages: first estimate a reduced-form object <span class="math inline">\(\pi\)</span>, then find the structural parameters <span class="math inline">\(\theta\)</span> that best fit the model’s implications for <span class="math inline">\(\pi\)</span>.</p>
<section id="setup" class="level3" data-number="13.5.1">
<h3 data-number="13.5.1" class="anchored" data-anchor-id="setup"><span class="header-section-number">13.5.1</span> Setup</h3>
<p>Let <span class="math inline">\(\psi(\pi,\theta)\)</span> be a vector of <span class="math inline">\(J\)</span> model restrictions satisfying <span class="math inline">\(\psi(\pi_{0},\theta_{0})=\mathbf{0}\)</span>. For example, in the savings model from <a href="extremum_intro_examples.html#exm-md_income" class="quarto-xref">Example&nbsp;<span>12.2</span></a>, <span class="math inline">\(\pi\)</span> consists of the variances of log income at each age, and <span class="math inline">\(\psi(\pi,\theta)=\pi - \mathbf{v}(\theta)\)</span> measures the gap between observed and model-implied moments.</p>
<p>Suppose we have a first-stage estimator <span class="math inline">\(\hat{\pi}\)</span> with: <span class="math display">\[\sqrt{N}(\hat{\pi}-\pi_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\Omega)\]</span></p>
<p>The minimum distance estimator is: <span class="math display">\[\hat{\theta} = \arg\min_{\theta}\psi(\hat{\pi},\theta)'\mathbf{W}_{N}\psi(\hat{\pi},\theta)\]</span> where <span class="math inline">\(\mathbf{W}_{N}\)</span> is a positive definite weighting matrix.</p>
</section>
<section id="asymptotic-distribution" class="level3" data-number="13.5.2">
<h3 data-number="13.5.2" class="anchored" data-anchor-id="asymptotic-distribution"><span class="header-section-number">13.5.2</span> Asymptotic Distribution</h3>
<div id="thm-md-asymptotics" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.7 (Asymptotics for Minimum Distance)</strong></span> Suppose:</p>
<ol type="1">
<li><span class="math inline">\(\psi(\pi_{0},\theta_{0})=\mathbf{0}\)</span> and <span class="math inline">\(\psi(\pi_{0},\theta)\neq\mathbf{0}\)</span> for all <span class="math inline">\(\theta\neq\theta_{0}\)</span> (<strong>identification</strong>)</li>
<li><span class="math inline">\(\sqrt{N}(\hat{\pi}-\pi_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\Omega)\)</span></li>
<li><span class="math inline">\(\mathbf{W}_{N}\rightarrow_{p}\mathbf{W}\)</span>, symmetric and nonsingular</li>
<li><span class="math inline">\(\psi\)</span> is differentiable with <span class="math inline">\(\text{rank}(\nabla_{\theta}\psi_{0})=p\)</span></li>
</ol>
<p>Define <span class="math inline">\(\nabla_{\theta}\psi_{0} = \frac{\partial\psi(\pi_{0},\theta_{0})'}{\partial\theta}\)</span> and <span class="math inline">\(\nabla_{\pi}\psi_{0}=\frac{\partial\psi(\pi_{0},\theta_{0})'}{\partial\pi}\)</span>. Then:</p>
<p><span class="math display">\[\sqrt{N}(\hat{\theta}-\theta_{0})\rightarrow_{d}\mathcal{N}(\mathbf{0},\ V_{MD})\]</span> where: <span class="math display">\[V_{MD} = \left(\nabla_{\theta}\psi_{0}\mathbf{W}\nabla_{\theta}\psi_{0}'\right)^{-1}\nabla_{\theta}\psi_{0}\mathbf{W}\nabla_{\pi}\psi_{0}'\Omega\nabla_{\pi}\psi_{0}\mathbf{W}\nabla_{\theta}\psi_{0}'\left(\nabla_{\theta}\psi_{0}\mathbf{W}\nabla_{\theta}\psi_{0}'\right)^{-1}\]</span></p>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Derivation Sketch
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The first-order condition of the minimum distance problem is: <span class="math display">\[\nabla_{\theta}\psi(\hat{\pi},\hat{\theta})\mathbf{W}_{N}\psi(\hat{\pi},\hat{\theta}) = \mathbf{0}\]</span></p>
<p>Expanding <span class="math inline">\(\psi(\hat{\pi},\hat{\theta})\)</span> around <span class="math inline">\((\pi_{0},\theta_{0})\)</span>: <span class="math display">\[\psi(\hat{\pi},\hat{\theta})\approx \nabla_{\pi}\psi_{0}'(\hat{\pi}-\pi_{0}) + \nabla_{\theta}\psi_{0}'(\hat{\theta}-\theta_{0})\]</span></p>
<p>Substituting and solving: <span class="math display">\[\sqrt{N}(\hat{\theta}-\theta_{0})\approx -(\nabla_{\theta}\psi_{0}\mathbf{W}\nabla_{\theta}\psi_{0}')^{-1}\nabla_{\theta}\psi_{0}\mathbf{W}\nabla_{\pi}\psi_{0}'\sqrt{N}(\hat{\pi}-\pi_{0})\]</span></p>
<p>The result follows from the asymptotic distribution of <span class="math inline">\(\hat{\pi}\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="the-optimal-weighting-matrix" class="level3" data-number="13.5.3">
<h3 data-number="13.5.3" class="anchored" data-anchor-id="the-optimal-weighting-matrix"><span class="header-section-number">13.5.3</span> The Optimal Weighting Matrix</h3>
<p>The variance <span class="math inline">\(V_{MD}\)</span> depends on the choice of <span class="math inline">\(\mathbf{W}\)</span>. The <strong>optimal</strong> weighting matrix minimizes <span class="math inline">\(V_{MD}\)</span> (in the positive semi-definite sense) and is given by:</p>
<p><span class="math display">\[\mathbf{W}^{*} = \left(\nabla_{\pi}\psi_{0}'\Omega\nabla_{\pi}\psi_{0}\right)^{-1}\]</span></p>
<p>Under this choice, the variance simplifies to: <span class="math display">\[V_{MD}^{*} = \left(\nabla_{\theta}\psi_{0}\left(\nabla_{\pi}\psi_{0}'\Omega\nabla_{\pi}\psi_{0}\right)^{-1}\nabla_{\theta}\psi_{0}'\right)^{-1}\]</span></p>
<p>In the common case where <span class="math inline">\(\psi(\pi,\theta) = \pi-h(\theta)\)</span> for some function <span class="math inline">\(h\)</span>, the derivatives simplify: <span class="math inline">\(\nabla_{\pi}\psi_{0} = I\)</span> and <span class="math inline">\(\nabla_{\theta}\psi_{0} = -\nabla_{\theta}h(\theta_{0})\)</span>. Then <span class="math inline">\(\mathbf{W}^{*}=\Omega^{-1}\)</span> and:</p>
<p><span class="math display">\[V_{MD}^{*} = \left(\nabla_{\theta}h_{0}\Omega^{-1}\nabla_{\theta}h_{0}'\right)^{-1}\]</span></p>
<p>An important special case arises when the model is <strong>just-identified</strong>: <span class="math inline">\(\text{dim}(\psi)=\text{dim}(\theta)\)</span>. In this case, one can show using the implicit function theorem that the optimally weighted minimum distance estimator achieves the same asymptotic variance as MLE. Over-identification (more moments than parameters) necessarily introduces some loss relative to MLE but gains robustness.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Standard Errors for the Income Process
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="exm-md_income_se" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.2</strong></span> Let’s extend the minimum distance estimation from <a href="extremum_intro_examples.html#exm-md_income" class="quarto-xref">Example&nbsp;<span>12.2</span></a> to compute standard errors for the income process parameters. Recall that we matched the variance of log income at each age to the model-implied variances.</p>
<p>Since our restrictions take the form <span class="math inline">\(\psi(\pi,\theta) = \pi - \mathbf{v}(\theta)\)</span>, we have <span class="math inline">\(\nabla_{\pi}\psi=I\)</span> and <span class="math inline">\(\nabla_{\theta}\psi = -\nabla_{\theta}\mathbf{v}\)</span>. Using the identity weighting matrix, the asymptotic variance is:</p>
<p><span class="math display">\[V_{MD} = (\nabla_{\theta}\mathbf{v}'\nabla_{\theta}\mathbf{v})^{-1}\nabla_{\theta}\mathbf{v}'\Omega\nabla_{\theta}\mathbf{v}(\nabla_{\theta}\mathbf{v}'\nabla_{\theta}\mathbf{v})^{-1}\]</span></p>
<p>where <span class="math inline">\(\Omega\)</span> is the variance-covariance matrix of the sample variance estimates <span class="math inline">\(\hat{\pi}\)</span>.</p>
<div id="1c3b96ae" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CSV</span>, <span class="bu">DataFrames</span>, <span class="bu">DataFramesMeta</span>, <span class="bu">Statistics</span>, <span class="bu">Optim</span>, <span class="bu">ForwardDiff</span>, <span class="bu">LinearAlgebra</span>, <span class="bu">Plots</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and prepare data</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>data_psid <span class="op">=</span> <span class="pp">@chain</span> <span class="cf">begin</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    CSV.<span class="fu">read</span>(<span class="st">"../data/abb_aea_data.csv"</span>,DataFrame,missingstring <span class="op">=</span> <span class="st">"NA"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@select</span> <span class="op">:</span>person <span class="op">:</span>y <span class="op">:</span>tot_assets1 <span class="op">:</span>asset <span class="op">:</span>age <span class="op">:</span>year</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@subset</span> <span class="op">:</span>age<span class="op">.&gt;=</span><span class="fl">25</span> <span class="op">:</span>age<span class="op">.&lt;=</span><span class="fl">64</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate sample variances by age</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>moments_df <span class="op">=</span> <span class="pp">@chain</span> data_psid <span class="cf">begin</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">groupby</span>(<span class="op">:</span>age)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@combine</span> <span class="cf">begin</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">:</span>var_logy <span class="op">=</span> <span class="fu">var</span>(<span class="fu">log</span>.(<span class="op">:</span>y))</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="op">:</span>n <span class="op">=</span> <span class="fu">length</span>(<span class="op">:</span>y)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="pp">@orderby</span> <span class="op">:</span>age</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>m_hat <span class="op">=</span> moments_df.var_logy</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>n_age <span class="op">=</span> moments_df.n</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Model-implied moments</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">model_moments</span>(θ, T)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    ρ, σ<span class="fl">2</span>_α, σ<span class="fl">2</span>_η <span class="op">=</span> θ</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> [σ<span class="fl">2</span>_α <span class="op">+</span> (<span class="fl">1</span><span class="op">-</span>ρ<span class="op">^</span>(<span class="fl">2</span>(t<span class="op">-</span><span class="fl">1</span>)))<span class="op">/</span>(<span class="fl">1</span><span class="op">-</span>ρ<span class="op">^</span><span class="fl">2</span>) <span class="op">*</span> σ<span class="fl">2</span>_η for t <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>T]</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> m</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform parameters to enforce constraints</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">transform</span>(x)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    ρ <span class="op">=</span> <span class="fu">tanh</span>(x[<span class="fl">1</span>])</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    σ<span class="fl">2</span>_α <span class="op">=</span> <span class="fu">exp</span>(x[<span class="fl">2</span>])</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    σ<span class="fl">2</span>_η <span class="op">=</span> <span class="fu">exp</span>(x[<span class="fl">3</span>])</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [ρ, σ<span class="fl">2</span>_α, σ<span class="fl">2</span>_η]</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimum distance objective (identity weight)</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">md_objective</span>(x, m_hat)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> <span class="fu">transform</span>(x)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="fu">length</span>(m_hat)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    m_model <span class="op">=</span> <span class="fu">model_moments</span>(θ, T)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> m_hat <span class="op">.-</span> m_model</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> diff<span class="op">'</span> <span class="op">*</span> diff</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fu">log</span>(<span class="fl">0.1</span>), <span class="fu">log</span>(<span class="fl">0.05</span>)]</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> <span class="fu">optimize</span>(x <span class="op">-&gt;</span> <span class="fu">md_objective</span>(x, m_hat), x0, <span class="fu">Newton</span>(), autodiff <span class="op">=</span> <span class="op">:</span>forward)</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>x_hat <span class="op">=</span> res.minimizer</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>θ_hat <span class="op">=</span> <span class="fu">transform</span>(x_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>3-element Vector{Float64}:
 0.9180604516854505
 0.27854304267515606
 0.08522314351469629</code></pre>
</div>
</div>
<p>Now we compute standard errors. We need <span class="math inline">\(\nabla_{\theta}\mathbf{v}\)</span> (the Jacobian of model moments with respect to parameters) and <span class="math inline">\(\Omega\)</span> (the variance of sample moments). We compute the Jacobian with <code>ForwardDiff</code> and use the delta method to account for the parameter transformation.</p>
<div id="61ae2804" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fu">length</span>(m_hat)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Jacobian of model moments w.r.t. θ = (ρ, σ²_α, σ²_η)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>∇v <span class="op">=</span> ForwardDiff.<span class="fu">jacobian</span>(θ <span class="op">-&gt;</span> <span class="fu">model_moments</span>(θ, T), θ_hat)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Jacobian of transform (for delta method through the transformation)</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>∇t <span class="op">=</span> ForwardDiff.<span class="fu">jacobian</span>(transform, x_hat)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate Ω: for variances, Var(σ̂²) ≈ 2σ⁴/(n-1) under normality</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># A simple approximation using sample sizes at each age</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>Ω <span class="op">=</span> <span class="fu">Diagonal</span>(<span class="fl">2</span> <span class="op">.*</span> m_hat<span class="op">.^</span><span class="fl">2</span> <span class="op">./</span> (n_age <span class="op">.-</span> <span class="fl">1</span>))</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Total sample size (use average n per age as approximation)</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>N_eff <span class="op">=</span> <span class="fu">Int</span>(<span class="fu">round</span>(<span class="fu">mean</span>(n_age)))</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Asymptotic variance of θ̂ (identity weighting)</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> ∇v  <span class="co"># J × p Jacobian</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>V_md <span class="op">=</span> <span class="fu">inv</span>(G<span class="op">'</span> <span class="op">*</span> G) <span class="op">*</span> G<span class="op">'</span> <span class="op">*</span> Ω <span class="op">*</span> G <span class="op">*</span> <span class="fu">inv</span>(G<span class="op">'</span> <span class="op">*</span> G) <span class="op">/</span> N_eff</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard errors</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_md))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Minimum Distance Estimates with Standard Errors:"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  ρ     = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat[<span class="fl">1</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se[<span class="fl">1</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  σ²_α  = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat[<span class="fl">2</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se[<span class="fl">2</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  σ²_η  = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat[<span class="fl">3</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se[<span class="fl">3</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum Distance Estimates with Standard Errors:
  ρ     = 0.918  (0.0005)
  σ²_α  = 0.279  (0.0009)
  σ²_η  = 0.085  (0.0005)</code></pre>
</div>
</div>
<p>We can also compute the standard errors under the <em>optimal</em> weighting matrix and compare:</p>
<div id="6febeaad" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimal weighting</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>W_opt <span class="op">=</span> <span class="fu">inv</span>(Ω)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>V_md_opt <span class="op">=</span> <span class="fu">inv</span>(G<span class="op">'</span> <span class="op">*</span> W_opt <span class="op">*</span> G) <span class="op">/</span> N_eff</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>se_opt <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_md_opt))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-estimate with optimal weighting</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">md_objective_opt</span>(x, m_hat, W)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    θ <span class="op">=</span> <span class="fu">transform</span>(x)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="fu">length</span>(m_hat)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    m_model <span class="op">=</span> <span class="fu">model_moments</span>(θ, T)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> m_hat <span class="op">.-</span> m_model</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> diff<span class="op">'</span> <span class="op">*</span> W <span class="op">*</span> diff</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>res_opt <span class="op">=</span> <span class="fu">optimize</span>(x <span class="op">-&gt;</span> <span class="fu">md_objective_opt</span>(x, m_hat, W_opt), x0, <span class="fu">Newton</span>(), autodiff <span class="op">=</span> <span class="op">:</span>forward)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>θ_hat_opt <span class="op">=</span> <span class="fu">transform</span>(res_opt.minimizer)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Recompute Jacobian at new estimates</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>∇v_opt <span class="op">=</span> ForwardDiff.<span class="fu">jacobian</span>(θ <span class="op">-&gt;</span> <span class="fu">model_moments</span>(θ, T), θ_hat_opt)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>V_md_opt2 <span class="op">=</span> <span class="fu">inv</span>(∇v_opt<span class="op">'</span> <span class="op">*</span> W_opt <span class="op">*</span> ∇v_opt) <span class="op">/</span> N_eff</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>se_opt2 <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_md_opt2))</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Optimally Weighted Estimates:"</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  ρ     = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat_opt[<span class="fl">1</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se_opt2[<span class="fl">1</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  σ²_α  = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat_opt[<span class="fl">2</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se_opt2[<span class="fl">2</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"  σ²_η  = </span><span class="sc">$</span>(<span class="fu">round</span>(θ_hat_opt[<span class="fl">3</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">  (</span><span class="sc">$</span>(<span class="fu">round</span>(se_opt2[<span class="fl">3</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Optimally Weighted Estimates:
  ρ     = 0.922  (0.0004)
  σ²_α  = 0.271  (0.0008)
  σ²_η  = 0.062  (0.0003)</code></pre>
</div>
</div>
<p>The optimally weighted estimator should be at least as precise, and is often substantially more so when the moment conditions have very different scales or variances.</p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="the-generalized-method-of-moments" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="the-generalized-method-of-moments"><span class="header-section-number">13.6</span> The Generalized Method of Moments</h2>
<p>GMM is an extremum estimator with objective: <span class="math display">\[Q_{N}(\theta) = -\frac{1}{2}\mathbf{g}_{N}(\theta)'\mathbf{W}_{N}\mathbf{g}_{N}(\theta),\qquad\mathbf{g}_{N}(\theta)=\frac{1}{N}\sum_{n}g(\mathbf{w}_{n},\theta)\]</span></p>
<p>where <span class="math inline">\(\mathbb{E}[g(\mathbf{w},\theta_{0})]=\mathbf{0}\)</span> are the moment conditions. The asymptotic distribution follows from <a href="#thm-asymptotic-normality" class="quarto-xref">Theorem&nbsp;<span>13.5</span></a> as a special case, but the structure of the problem leads to a particularly clean expression.</p>
<div id="thm-gmm-asymptotics" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13.8 (Asymptotic Distribution of GMM)</strong></span> Suppose that the standard regularity conditions hold and <span class="math inline">\(\mathbf{W}_{N}\rightarrow_{p}\mathbf{W}\)</span>. Let <span class="math inline">\(G=\mathbb{E}[\nabla_{\theta}g(\mathbf{w},\theta_{0})']\)</span> and <span class="math inline">\(S=\mathbb{E}[g(\mathbf{w},\theta_{0})g(\mathbf{w},\theta_{0})']\)</span>. Then:</p>
<p><span class="math display">\[\sqrt{N}(\hat{\theta}_{GMM}-\theta_{0})\rightarrow_{d}\mathcal{N}\left(\mathbf{0},\ (G'\mathbf{W}G)^{-1}G'\mathbf{W}S\mathbf{W}G(G'\mathbf{W}G)^{-1}\right)\]</span></p>
</div>
<section id="the-optimal-weighting-matrix-1" class="level3" data-number="13.6.1">
<h3 data-number="13.6.1" class="anchored" data-anchor-id="the-optimal-weighting-matrix-1"><span class="header-section-number">13.6.1</span> The Optimal Weighting Matrix</h3>
<p>As with minimum distance, the asymptotic variance depends on the choice of <span class="math inline">\(\mathbf{W}\)</span>. The optimal weighting matrix is:</p>
<p><span class="math display">\[\mathbf{W}^{*}=S^{-1} = \left(\mathbb{E}[g(\mathbf{w},\theta_{0})g(\mathbf{w},\theta_{0})']\right)^{-1}\]</span></p>
<p>Under this choice, the variance simplifies to:</p>
<p><span class="math display">\[V_{GMM}^{*} = (G'S^{-1}G)^{-1}\]</span></p>
<p>When the model is <strong>just-identified</strong> (number of moments equals number of parameters), the GMM estimator does not depend on <span class="math inline">\(\mathbf{W}\)</span> at all. This is because the sample moments <span class="math inline">\(\mathbf{g}_{N}(\hat{\theta})=\mathbf{0}\)</span> are set exactly to zero, regardless of the weighting.</p>
</section>
<section id="feasible-efficient-gmm" class="level3" data-number="13.6.2">
<h3 data-number="13.6.2" class="anchored" data-anchor-id="feasible-efficient-gmm"><span class="header-section-number">13.6.2</span> Feasible Efficient GMM</h3>
<p>In practice, <span class="math inline">\(S\)</span> depends on <span class="math inline">\(\theta_{0}\)</span> and must be estimated. A common approach is <strong>two-step GMM</strong>:</p>
<ol type="1">
<li>Estimate <span class="math inline">\(\hat{\theta}_{1}\)</span> using some initial weighting matrix (e.g.&nbsp;<span class="math inline">\(\mathbf{W}=I\)</span>).</li>
<li>Compute <span class="math inline">\(\hat{S}=\frac{1}{N}\sum_{n}g(\mathbf{w}_{n},\hat{\theta}_{1})g(\mathbf{w}_{n},\hat{\theta}_{1})'\)</span>.</li>
<li>Re-estimate: <span class="math inline">\(\hat{\theta}_{2} = \arg\min_{\theta}\mathbf{g}_{N}(\theta)'\hat{S}^{-1}\mathbf{g}_{N}(\theta)\)</span>.</li>
</ol>
<p>The resulting estimator <span class="math inline">\(\hat{\theta}_{2}\)</span> is asymptotically efficient. The first-stage estimation of <span class="math inline">\(\hat{S}\)</span> does not affect the asymptotic variance because <span class="math inline">\(\hat{S}\rightarrow_{p}S\)</span> under standard conditions, and the weighting matrix appears in the asymptotic variance only through its probability limit.</p>
</section>
</section>
<section id="two-step-estimators" class="level2" data-number="13.7">
<h2 data-number="13.7" class="anchored" data-anchor-id="two-step-estimators"><span class="header-section-number">13.7</span> Two-Step Estimators</h2>
<p>Many structural estimators proceed in stages. In <a href="identification_roy.html#exm-roy_estimation" class="quarto-xref">Example&nbsp;<span>7.1</span></a>, we first estimated the selection equation by MLE and then used these estimates in a second-stage OLS regression. In the search model, we might first estimate the wage distribution and then back out the reservation wage. The theory of <em>two-step estimators</em> formalizes the effect of first-stage estimation uncertainty on second-stage inference.</p>
<section id="setup-1" class="level3" data-number="13.7.1">
<h3 data-number="13.7.1" class="anchored" data-anchor-id="setup-1"><span class="header-section-number">13.7.1</span> Setup</h3>
<p>Suppose the estimator is defined by two sets of moment conditions:</p>
<ol type="1">
<li><strong>First step</strong>: Estimate <span class="math inline">\(\hat{\gamma}\)</span> via <span class="math inline">\(\frac{1}{N}\sum_{n}g_{1}(\mathbf{w}_{n},\hat{\gamma})=\mathbf{0}\)</span></li>
<li><strong>Second step</strong>: Estimate <span class="math inline">\(\hat{\beta}\)</span> via <span class="math inline">\(\frac{1}{N}\sum_{n}g_{2}(\mathbf{w}_{n},\hat{\gamma},\hat{\beta})=\mathbf{0}\)</span></li>
</ol>
<p>The key feature is that the second step depends on the first-step estimates.</p>
</section>
<section id="asymptotic-distribution-1" class="level3" data-number="13.7.2">
<h3 data-number="13.7.2" class="anchored" data-anchor-id="asymptotic-distribution-1"><span class="header-section-number">13.7.2</span> Asymptotic Distribution</h3>
<p>To derive the joint distribution, stack the moment conditions. Let <span class="math inline">\(\alpha=(\gamma',\beta')'\)</span> and write the full system as: <span class="math display">\[\frac{1}{N}\sum_{n}\begin{bmatrix}g_{1}(\mathbf{w}_{n},\gamma)\\ g_{2}(\mathbf{w}_{n},\gamma,\beta)\end{bmatrix} = \mathbf{0}\]</span></p>
<p>The Jacobian of this system has a <strong>block-triangular</strong> structure: <span class="math display">\[\Gamma = \begin{bmatrix}\Gamma_{1\gamma} &amp; 0 \\ \Gamma_{2\gamma} &amp; \Gamma_{2\beta}\end{bmatrix}\]</span></p>
<p>where <span class="math inline">\(\Gamma_{1\gamma}=\mathbb{E}[\nabla_{\gamma}g_{1}']\)</span>, <span class="math inline">\(\Gamma_{2\gamma}=\mathbb{E}[\nabla_{\gamma}g_{2}']\)</span>, and <span class="math inline">\(\Gamma_{2\beta}=\mathbb{E}[\nabla_{\beta}g_{2}']\)</span>. The zero in the upper-right block reflects the fact that the first step does not depend on <span class="math inline">\(\beta\)</span>.</p>
<p>Applying the standard GMM formula, the asymptotic variance of <span class="math inline">\(\hat{\beta}\)</span> is:</p>
<p><span class="math display">\[V_{\beta} = \Gamma_{2\beta}^{-1}\mathbb{E}[(g_{2}-\Gamma_{2\gamma}\Gamma_{1\gamma}^{-1}g_{1})(g_{2}-\Gamma_{2\gamma}\Gamma_{1\gamma}^{-1}g_{1})']\Gamma_{2\beta}^{-1\prime}\]</span></p>
<p>The term <span class="math inline">\(\Gamma_{2\gamma}\Gamma_{1\gamma}^{-1}g_{1}\)</span> captures the <em>correction</em> for first-stage estimation error. If we ignored this term and computed standard errors using only the second-stage moment conditions, we would generally get incorrect inference.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
When Does the First Stage Not Matter?
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is an important special case: if <span class="math inline">\(\Gamma_{2\gamma}=\mathbb{E}[\nabla_{\gamma}g_{2}']=0\)</span>, then the correction vanishes and the first-stage estimation has no effect on the second-stage asymptotic variance. Intuitively, this happens when the second-step moment conditions are <em>locally insensitive</em> to the first-step parameters at the true values.</p>
<p>A classic example is the <strong>two-stage IV</strong> estimator where the first stage is a probit. Here, the second-stage moment condition takes the form <span class="math inline">\(\mathbb{E}[\Phi(\mathbf{x}'\gamma_{0})\cdot u]=0\)</span>. One can show that <span class="math inline">\(\mathbb{E}[\nabla_{\gamma}g_{2}']=0\)</span> because the projection of <span class="math inline">\(u\)</span> onto functions of the instruments is zero by construction.</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Two-Step Roy Model with Standard Errors
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="exm-two_step_roy_se" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.3</strong></span> Let’s revisit the two-step estimator for the Generalized Roy Model, now accounting for first-stage estimation uncertainty. In the first step we estimate the probit, and in the second step we run the selection-corrected OLS regression.</p>
<p>The second-step regression for the treated group is: <span class="math display">\[Y = X\beta_{1} - \sigma_{V1}\frac{\phi(W\gamma)}{\Phi(W\gamma)} + \text{error}\]</span></p>
<p>Since the selection correction depends on <span class="math inline">\(\hat{\gamma}\)</span>, we need to account for first-stage variability.</p>
<div id="a3e97919" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Distributions</span>, <span class="bu">Optim</span>, <span class="bu">Random</span>, <span class="bu">ForwardDiff</span>, <span class="bu">LinearAlgebra</span>, <span class="bu">Plots</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Reuse sim_data and estimate_probit from above</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Two-step estimation with standard errors</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">two_step_with_se</span>(data, N)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    (;X,Z,Y,D) <span class="op">=</span> data</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: Probit</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    γ_hat <span class="op">=</span> <span class="fu">estimate_probit</span>(data)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute first-stage information matrix</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    H1 <span class="op">=</span> ForwardDiff.<span class="fu">hessian</span>(g <span class="op">-&gt;</span> <span class="fu">log_likelihood</span>(g, data), γ_hat)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    V_gamma <span class="op">=</span> <span class="fu">-inv</span>(H1) <span class="op">/</span> N</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Selection-corrected OLS for treated group</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> <span class="fu">hcat</span>(<span class="fu">ones</span>(N), X, Z)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> W <span class="op">*</span> γ_hat</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    correction1 <span class="op">=</span> <span class="fu">pdf</span>.(<span class="fu">Normal</span>(), idx) <span class="op">./</span> <span class="fu">cdf</span>.(<span class="fu">Normal</span>(), idx)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    Y1 <span class="op">=</span> Y[D <span class="op">.==</span> <span class="fl">1</span>]</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    X1_mat <span class="op">=</span> <span class="fu">hcat</span>(<span class="fu">ones</span>(<span class="fu">sum</span>(D)), X[D <span class="op">.==</span> <span class="fl">1</span>], correction1[D <span class="op">.==</span> <span class="fl">1</span>])</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    β<span class="fl">1</span>_hat <span class="op">=</span> X1_mat <span class="op">\</span> Y1</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For correct standard errors, we need the influence function approach</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The second-stage residuals</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    resid1 <span class="op">=</span> Y1 <span class="op">.-</span> X1_mat <span class="op">*</span> β<span class="fl">1</span>_hat</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    N1 <span class="op">=</span> <span class="fu">sum</span>(D)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Naive OLS variance (ignoring first stage)</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    V_naive <span class="op">=</span> <span class="fu">inv</span>(X1_mat<span class="op">'</span> <span class="op">*</span> X1_mat) <span class="op">*</span> (X1_mat<span class="op">'</span> <span class="op">*</span> <span class="fu">Diagonal</span>(resid1<span class="op">.^</span><span class="fl">2</span>) <span class="op">*</span> X1_mat) <span class="op">*</span> <span class="fu">inv</span>(X1_mat<span class="op">'</span> <span class="op">*</span> X1_mat)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Correction: how the selection term responds to γ</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ∂correction1/∂γ for each observation</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span> <span class="fu">correction_grad</span>(n, γ)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> [<span class="fl">1</span>., X[n], Z[n]]</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>        xg <span class="op">=</span> <span class="fu">dot</span>(w, γ)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>        ϕ <span class="op">=</span> <span class="fu">pdf</span>(<span class="fu">Normal</span>(), xg)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        Φ <span class="op">=</span> <span class="fu">cdf</span>(<span class="fu">Normal</span>(), xg)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># d/dγ [ϕ(wγ)/Φ(wγ)] = [-xg*ϕ/Φ - ϕ²/Φ²] * w</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        dcorr <span class="op">=</span> (<span class="op">-</span>xg <span class="op">*</span> ϕ <span class="op">/</span> Φ <span class="op">-</span> ϕ<span class="op">^</span><span class="fl">2</span> <span class="op">/</span> Φ<span class="op">^</span><span class="fl">2</span>) <span class="op">.*</span> w</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> dcorr</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">end</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute Γ_{2γ} = E[∂g₂/∂γ']</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># g₂ = X₁'(Y₁ - X₁β₁) where X₁ depends on γ through the correction term</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The effect of γ on the moment is through the correction term</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>    treated_idx <span class="op">=</span> <span class="fu">findall</span>(D <span class="op">.==</span> <span class="fl">1</span>)</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>    Gamma_2gamma <span class="op">=</span> <span class="fu">zeros</span>(<span class="fl">3</span>, <span class="fl">3</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (j, n) <span class="kw">in</span> <span class="fu">enumerate</span>(treated_idx)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>        dc <span class="op">=</span> <span class="fu">correction_grad</span>(n, γ_hat)</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>        Gamma_2gamma <span class="op">+=</span> <span class="op">-</span>β<span class="fl">1</span>_hat[<span class="fl">3</span>] <span class="op">*</span> [<span class="fl">0</span>. <span class="fl">0</span>. <span class="fl">0</span>.; <span class="fl">0</span>. <span class="fl">0</span>. <span class="fl">0</span>.; dc<span class="op">'</span>] <span class="op">/</span> N1</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The correction also affects X1_mat column 3</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>        Gamma_2gamma <span class="op">+=</span> <span class="op">-</span>[<span class="fl">1</span>., X[n], correction1[n]] <span class="op">*</span> dc<span class="op">'</span> <span class="op">*</span> resid1[j] <span class="op">/</span> (N1 <span class="op">*</span> correction1[n]) <span class="co"># approximation</span></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (;γ_hat, β<span class="fl">1</span>_hat, se_naive <span class="op">=</span> <span class="fu">sqrt</span>.(<span class="fu">diag</span>(V_naive)),</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>             V_gamma, Gamma_2gamma)</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.5</span>, <span class="fl">0.5</span>]</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.3</span>]</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>beta1 <span class="op">=</span> [<span class="fl">0</span>., <span class="fl">0.5</span>]</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a><span class="bu">Random</span>.<span class="fu">seed!</span>(<span class="fl">42</span>)</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="fu">sim_data</span>(gamma, beta0, beta1, <span class="fl">5000</span>)</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> <span class="fu">two_step_with_se</span>(data, <span class="fl">5000</span>)</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Second-stage estimates: </span><span class="sc">$</span>(<span class="fu">round</span>.(results.β<span class="fl">1</span>_hat[<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>], digits<span class="op">=</span><span class="fl">3</span>))<span class="st">"</span>)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Naive SE:              </span><span class="sc">$</span>(<span class="fu">round</span>.(results.se_naive[<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>], digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Second-stage estimates: [-0.106, 0.508]
Naive SE:              [0.0633, 0.0283]</code></pre>
</div>
</div>
<p>A robust way to check the standard errors is to compare with a Monte Carlo simulation, which we already did for the probit in <a href="#exm-probit_se" class="quarto-xref">Example&nbsp;<span>13.1</span></a>. The correction matters most when the selection correction term is strongly estimated and when the first-stage parameters are imprecisely estimated.</p>
<div id="2414a220" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Monte Carlo to verify</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>ests <span class="op">=</span> <span class="fu">mapreduce</span>(vcat, <span class="fl">1</span><span class="op">:</span><span class="fl">500</span>) <span class="cf">do</span> b</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="fu">sim_data</span>(gamma, beta0, beta1, <span class="fl">2000</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    γ_hat <span class="op">=</span> <span class="fu">estimate_probit</span>(d)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> <span class="fu">hcat</span>(<span class="fu">ones</span>(<span class="fl">2000</span>), d.X, d.Z)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> W <span class="op">*</span> γ_hat</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    corr <span class="op">=</span> <span class="fu">pdf</span>.(<span class="fu">Normal</span>(), idx) <span class="op">./</span> <span class="fu">cdf</span>.(<span class="fu">Normal</span>(), idx)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    Y1 <span class="op">=</span> d.Y[d.D <span class="op">.==</span> <span class="fl">1</span>]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    X1 <span class="op">=</span> <span class="fu">hcat</span>(<span class="fu">ones</span>(<span class="fu">sum</span>(d.D)), d.X[d.D <span class="op">.==</span> <span class="fl">1</span>], corr[d.D <span class="op">.==</span> <span class="fl">1</span>])</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> X1 <span class="op">\</span> Y1</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> β[<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>]<span class="ch">'</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="st">"Monte Carlo SD of β₁: </span><span class="sc">$</span>(<span class="fu">round</span>.(<span class="fu">std</span>.(<span class="fu">eachcol</span>(ests)), digits<span class="op">=</span><span class="fl">4</span>))<span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Monte Carlo SD of β₁: [0.0928, 0.0441]</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Discussion: Bootstrap vs.&nbsp;Analytical Standard Errors
</div>
</div>
<div class="callout-body-container callout-body">
<p>Computing analytical standard errors for two-step estimators can be tedious, as the example above illustrates. An attractive alternative is the <strong>bootstrap</strong>: resample the data, re-run the entire two-step procedure on each bootstrap sample, and compute standard errors from the distribution of bootstrap estimates. This automatically accounts for first-stage estimation uncertainty without requiring explicit computation of correction terms. We will discuss the bootstrap formally in the chapter on <a href="../lectures/simulation-methods.html">simulation methods</a>.</p>
</div>
</div>
</section>
</section>
<section id="exercises" class="level2" data-number="13.8">
<h2 data-number="13.8" class="anchored" data-anchor-id="exercises"><span class="header-section-number">13.8</span> Exercises</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-search_se" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.1</strong></span> Extend <a href="extremum_intro_examples.html#exm-search_likelihood" class="quarto-xref">Example&nbsp;<span>12.1</span></a> to:</p>
<ol type="1">
<li>Compute asymptotic standard errors for the estimated parameters <span class="math inline">\(\hat{\theta}=(h,\delta,\mu,\sigma,w^{*})\)</span> using the information matrix.</li>
<li>Use the delta method (or <code>ForwardDiff</code>) to compute standard errors for the derived estimates <span class="math inline">\(\hat{\lambda}\)</span> and <span class="math inline">\(\hat{b}\)</span>.</li>
<li>Estimate the search model separately for men with and without a bachelor’s degree.</li>
<li>Report and compare your estimates. Are the differences across education groups economically meaningful? What does the model imply about the sources of wage differences between these groups?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-bpp" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.2</strong></span> <span class="citation" data-cites="BPP2008">Blundell, Pistaferri, and Preston (<a href="../references.html#ref-BPP2008" role="doc-biblioref">2008</a>)</span> estimate income and consumption dynamics using a model where: <span class="math display">\[\Delta y_{n,t} = \zeta_{n,t} + \Delta\xi_{n,t}\]</span> where <span class="math inline">\(\zeta_{n,t}\)</span> is a permanent shock and <span class="math inline">\(\xi_{n,t}\)</span> is a transitory shock. Consumption responds differently to each: <span class="math display">\[\Delta c_{n,t} = \phi\zeta_{n,t} + \psi\xi_{n,t} + \epsilon_{n,t}\]</span> where <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\psi\)</span> capture the “insurance coefficients” — the degree to which consumption responds to permanent and transitory income shocks, respectively.</p>
<ol type="1">
<li>Show that from the second moments of <span class="math inline">\((\Delta y, \Delta c)\)</span>, one can identify <span class="math inline">\(\sigma^{2}_{\zeta}\)</span>, <span class="math inline">\(\sigma^{2}_{\xi}\)</span>, <span class="math inline">\(\phi\)</span>, and <span class="math inline">\(\psi\)</span>. <em>Hint</em>: consider <span class="math inline">\(\mathbb{V}[\Delta y_{t}]\)</span>, <span class="math inline">\(\mathbb{C}(\Delta y_{t},\Delta y_{t-1})\)</span>, <span class="math inline">\(\mathbb{C}(\Delta c_{t},\Delta y_{t})\)</span>, and <span class="math inline">\(\mathbb{C}(\Delta c_{t},\Delta y_{t-1})\)</span>.</li>
<li>Using the data from <a href="identification_savings.html#exm-psid" class="quarto-xref">Example&nbsp;<span>10.1</span></a>, implement a minimum distance estimator for <span class="math inline">\((\sigma^{2}_{\zeta},\sigma^{2}_{\xi},\phi,\psi)\)</span> and report standard errors.</li>
<li>What do the estimates of <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\psi\)</span> tell us about how well households insure against permanent versus transitory income shocks?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exr-entry_exit_md" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.3</strong></span> Consider estimation of the entry-exit model by minimum distance, as described in the <a href="../lectures/extremum_intro_examples.html">introduction</a>. Recall that for each state <span class="math inline">\((x,a,a')\)</span>, the model implies a choice probability <span class="math inline">\(p(x,a,a';\phi,\beta)\)</span> that depends on the payoff parameters through the equilibrium of the game. Data consist of entry decisions across many independent markets.</p>
<ol type="1">
<li>Simulate data from the entry-exit model for <span class="math inline">\(M=500\)</span> markets at 5 equally spaced values of <span class="math inline">\(x\)</span> and use the empirical choice frequencies as your target moments <span class="math inline">\(\hat{\mathbf{p}}\)</span>.</li>
<li>Implement the minimum distance estimator: <span class="math display">\[\hat{\phi} = \arg\min_{\phi}(\hat{\mathbf{p}}-\mathbf{p}(\phi,\beta))'\mathbf{W}(\hat{\mathbf{p}}-\mathbf{p}(\phi,\beta))\]</span> using the identity weighting matrix. <em>Note</em>: for each candidate <span class="math inline">\(\phi\)</span>, you must solve for the equilibrium to compute <span class="math inline">\(\mathbf{p}(\phi,\beta)\)</span>.</li>
<li>Compute standard errors for <span class="math inline">\(\hat{\phi}\)</span> using the minimum distance variance formula from <a href="#thm-md-asymptotics" class="quarto-xref">Theorem&nbsp;<span>13.7</span></a>.</li>
<li>Re-estimate with the optimal weighting matrix and compare your standard errors.</li>
</ol>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-BPP2008" class="csl-entry" role="listitem">
Blundell, Richard, Luigi Pistaferri, and Ian Preston. 2008. <span>“Consumption Inequality and Partial Insurance.”</span> <em>American Economic Review</em> 98 (5).
</div>
<div id="ref-newey1994large" class="csl-entry" role="listitem">
Newey, Whitney K, and Daniel McFadden. 1994. <span>“Large Sample Estimation and Hypothesis Testing.”</span> <em>Handbook of Econometrics</em> 4: 2111–2245.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../lectures/extremum_intro_examples.html" class="pagination-link" aria-label="Introducing the Estimators with Examples">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introducing the Estimators with Examples</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../lectures/simulation-methods.html" class="pagination-link" aria-label="Simulation Methods">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Simulation Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>